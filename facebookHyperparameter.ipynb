{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Walk Length 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ayush\\AppData\\Local\\Temp\\ipykernel_45780\\677807264.py:178: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_df = pd.concat([results_df, pd.DataFrame([{'seed': seed, 'p': p, 'q': q, 'roc_auc': test_roc_auc}])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   seed     p     q   roc_auc\n",
      "0     0  0.25  0.25  0.887377\n",
      "1     0  0.25  0.50  0.909079\n",
      "2     0  0.25  1.00  0.893868\n",
      "3     0  0.25  2.00  0.903424\n",
      "4     0  0.25  3.00  0.884476\n",
      "5     0  0.25  4.00  0.896868\n",
      "6     0  0.50  0.25  0.907702\n",
      "7     0  0.50  0.50  0.913455\n",
      "8     0  0.50  1.00  0.903227\n",
      "9     0  0.50  2.00  0.890295\n",
      "10    0  0.50  3.00  0.915996\n",
      "11    0  0.50  4.00  0.909817\n",
      "12    0  1.00  0.25  0.898982\n",
      "13    0  1.00  0.50  0.909308\n",
      "14    0  1.00  1.00  0.903129\n",
      "15    0  1.00  2.00  0.921651\n",
      "16    0  1.00  3.00  0.909554\n",
      "17    0  1.00  4.00  0.900310\n",
      "18    0  2.00  0.25  0.898441\n",
      "19    0  2.00  0.50  0.913914\n",
      "20    0  2.00  1.00  0.895720\n",
      "21    0  2.00  2.00  0.894327\n",
      "22    0  2.00  3.00  0.887689\n",
      "23    0  2.00  4.00  0.901392\n",
      "24    0  3.00  0.25  0.912242\n",
      "25    0  3.00  0.50  0.924241\n",
      "26    0  3.00  1.00  0.909849\n",
      "27    0  3.00  2.00  0.911013\n",
      "28    0  3.00  3.00  0.908161\n",
      "29    0  3.00  4.00  0.898179\n",
      "30    0  4.00  0.25  0.910980\n",
      "31    0  4.00  0.50  0.914734\n",
      "32    0  4.00  1.00  0.901326\n",
      "33    0  4.00  2.00  0.910980\n",
      "34    0  4.00  3.00  0.897687\n",
      "35    0  4.00  4.00  0.899277\n",
      "Best combination of p and q: (3.0, 0.5)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import networkx as nx\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Function to load edge list from a file\n",
    "def load_edgelist(file_path):\n",
    "    edges = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            edge = line.strip().split()\n",
    "            edges.append((edge[0], edge[1]))\n",
    "    return edges\n",
    "\n",
    "# Function to sample a subgraph using BFS\n",
    "def sample_subgraph_bfs(graph, start_node=None, number_of_nodes=1000, seed=None):\n",
    "    if start_node is None:\n",
    "        nodes = list(graph.nodes())\n",
    "        random.Random(seed).shuffle(nodes)\n",
    "        start_node = nodes[0]\n",
    "\n",
    "    sampled_nodes = set([start_node])\n",
    "    node_queue = [start_node]\n",
    "\n",
    "    while len(sampled_nodes) < number_of_nodes and node_queue:\n",
    "        current = node_queue.pop(0)\n",
    "        neighbors = sorted(list(graph.neighbors(current)))\n",
    "        random.Random(seed).shuffle(neighbors)\n",
    "\n",
    "        for neighbor in neighbors:\n",
    "            if len(sampled_nodes) >= number_of_nodes:\n",
    "                break\n",
    "            if neighbor not in sampled_nodes:\n",
    "                sampled_nodes.add(neighbor)\n",
    "                node_queue.append(neighbor)\n",
    "\n",
    "    return graph.subgraph(sampled_nodes)\n",
    "\n",
    "# Function to generate edge embeddings\n",
    "def generate_edge_embeddings(edges, embedding_function):\n",
    "    edge_embeddings = []\n",
    "    for u, v in edges:\n",
    "        u_embedding = embedding_function(u)\n",
    "        v_embedding = embedding_function(v)\n",
    "        edge_embedding = np.multiply(u_embedding, v_embedding)\n",
    "        edge_embeddings.append(edge_embedding)\n",
    "    return np.array(edge_embeddings)\n",
    "\n",
    "# Function to split the graph into train and test sets, ensuring connectivity\n",
    "def split_graph_with_connectivity(graph, fraction_to_remove=0.1, seed=None):\n",
    "    edge_list = list(graph.edges())\n",
    "    num_edges_to_remove = int(fraction_to_remove * graph.number_of_edges())\n",
    "\n",
    "    while True:\n",
    "        random.Random(seed).shuffle(edge_list)\n",
    "        edges_to_remove = edge_list[:num_edges_to_remove]\n",
    "        G_train = graph.copy()\n",
    "        G_train.remove_edges_from(edges_to_remove)\n",
    "        if nx.is_connected(G_train):\n",
    "            break\n",
    "\n",
    "    G_test = graph.copy()\n",
    "    G_test.remove_edges_from(G_train.edges())\n",
    "\n",
    "    return G_train, G_test, edges_to_remove\n",
    "\n",
    "# Function to generate positive and negative samples\n",
    "def generate_samples(graph, seed=None):\n",
    "    positive_samples = list(graph.edges())\n",
    "    negative_samples = []\n",
    "    all_nodes = sorted(list(graph.nodes()))\n",
    "\n",
    "    while len(negative_samples) < len(positive_samples):\n",
    "        node_pair = random.sample(all_nodes, 2)\n",
    "        if not graph.has_edge(*node_pair):\n",
    "            negative_samples.append(tuple(sorted(node_pair)))\n",
    "\n",
    "    return positive_samples, negative_samples\n",
    "\n",
    "# Function to generate Node2Vec embeddings\n",
    "def generate_node2vec_embeddings(graph, dimensions=128, num_walks=30, walk_length=10, p=1.0, q=1.0, seed=None):\n",
    "    # Function to perform random walk based on Node2Vec algorithm\n",
    "    def node2vec_walk(node):\n",
    "        walk = [node]\n",
    "        for _ in range(walk_length):\n",
    "            neighbors = list(graph.neighbors(walk[-1]))\n",
    "            if len(neighbors) > 0:\n",
    "                if len(walk) == 1:\n",
    "                    walk.append(random.choice(neighbors))\n",
    "                else:\n",
    "                    prev_node = walk[-2]\n",
    "                    probs = []\n",
    "                    for neighbor in neighbors:\n",
    "                        if neighbor == prev_node:\n",
    "                            probs.append(1 / p)\n",
    "                        elif graph.has_edge(prev_node, neighbor):\n",
    "                            probs.append(1)\n",
    "                        else:\n",
    "                            probs.append(1 / q)\n",
    "                    probs = np.array(probs)\n",
    "                    probs /= np.sum(probs)\n",
    "                    walk.append(np.random.choice(neighbors, p=probs))\n",
    "            else:\n",
    "                break\n",
    "        return walk\n",
    "\n",
    "    # Generating random walks\n",
    "    walks = []\n",
    "    nodes = list(graph.nodes())\n",
    "    for _ in range(num_walks):\n",
    "        random.seed(seed)\n",
    "        random.shuffle(nodes)\n",
    "        for node in nodes:\n",
    "            walks.append(node2vec_walk(node))\n",
    "\n",
    "    # Learning embeddings using Word2Vec with a fixed seed\n",
    "    embeddings = {}\n",
    "    model = Word2Vec(walks, vector_size=dimensions, window=5, min_count=1, sg=1, workers=1, seed=seed)\n",
    "    for node in nodes:\n",
    "        embeddings[node] = model.wv[node]\n",
    "\n",
    "    # Function to get node embeddings\n",
    "    def embedding_function(u):\n",
    "        return embeddings[u]\n",
    "\n",
    "    return model, embedding_function\n",
    "\n",
    "# Grid search over p, q ∈ {0.25, 0.50, 1, 2}\n",
    "p_values = [0.25, 0.5, 1, 2,3,4]\n",
    "q_values = [0.25, 0.5, 1, 2,3,4]\n",
    "\n",
    "# DataFrame to store the results\n",
    "results_df = pd.DataFrame(columns=['seed', 'p', 'q', 'roc_auc'])\n",
    "\n",
    "for seed in range(1):\n",
    "    # Set the new random seed for all functions\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "    # Load the data and create the graph\n",
    "    edge_list = load_edgelist('facebook_combined.txt')  # Replace with your actual file path\n",
    "    G = nx.Graph()\n",
    "    G.add_edges_from(edge_list)\n",
    "\n",
    "    # Sample subgraph, split into train/test, generate samples\n",
    "    subgraph = sample_subgraph_bfs(G, number_of_nodes=300, seed=seed)\n",
    "    G_train, G_test, _ = split_graph_with_connectivity(subgraph, seed=seed)\n",
    "    positive_samples_train, negative_samples_train = generate_samples(G_train, seed=seed)\n",
    "    positive_samples_test, negative_samples_test = generate_samples(G_test, seed=seed)\n",
    "\n",
    "    for p in p_values:\n",
    "        for q in q_values:\n",
    "            # Node2Vec embeddings\n",
    "            _, embedding_function = generate_node2vec_embeddings(G_train, p=p, q=q, seed=seed)\n",
    "\n",
    "            # Generate edge embeddings\n",
    "            edge_embeddings_train = generate_edge_embeddings(positive_samples_train + negative_samples_train, embedding_function)\n",
    "            edge_embeddings_test = generate_edge_embeddings(positive_samples_test + negative_samples_test, embedding_function)\n",
    "\n",
    "            # Logistic Regression Model\n",
    "            labels_train = np.array([1] * len(positive_samples_train) + [0] * len(negative_samples_train))\n",
    "            lr_clf = LogisticRegressionCV(cv=10, max_iter=2000, scoring=\"roc_auc\", random_state=seed)\n",
    "            classifier = lr_clf.fit(edge_embeddings_train, labels_train)\n",
    "\n",
    "            # Evaluate the model\n",
    "            labels_test = np.array([1] * len(positive_samples_test) + [0] * len(negative_samples_test))\n",
    "            test_predictions = classifier.predict_proba(edge_embeddings_test)[:, 1]\n",
    "            test_roc_auc = roc_auc_score(labels_test, test_predictions)\n",
    "\n",
    "            # Store results\n",
    "            results_df = pd.concat([results_df, pd.DataFrame([{'seed': seed, 'p': p, 'q': q, 'roc_auc': test_roc_auc}])], ignore_index=True)\n",
    "\n",
    "# Print DataFrame\n",
    "print(results_df)\n",
    "\n",
    "# Find the best combination of p and q based on average ROC AUC\n",
    "best_combination = results_df.groupby(['p', 'q'])['roc_auc'].mean().idxmax()\n",
    "print(f\"Best combination of p and q: {best_combination}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Walk Length 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ayush\\AppData\\Local\\Temp\\ipykernel_45780\\1798957508.py:178: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_df = pd.concat([results_df, pd.DataFrame([{'seed': seed, 'p': p, 'q': q, 'roc_auc': test_roc_auc}])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   seed     p     q   roc_auc\n",
      "0     0  0.25  0.25  0.906489\n",
      "1     0  0.25  0.50  0.910734\n",
      "2     0  0.25  1.00  0.891623\n",
      "3     0  0.25  2.00  0.874707\n",
      "4     0  0.25  3.00  0.904490\n",
      "5     0  0.25  4.00  0.892754\n",
      "6     0  0.50  0.25  0.906817\n",
      "7     0  0.50  0.50  0.906014\n",
      "8     0  0.50  1.00  0.891147\n",
      "9     0  0.50  2.00  0.903031\n",
      "10    0  0.50  3.00  0.901277\n",
      "11    0  0.50  4.00  0.881591\n",
      "12    0  1.00  0.25  0.916717\n",
      "13    0  1.00  0.50  0.910587\n",
      "14    0  1.00  1.00  0.905276\n",
      "15    0  1.00  2.00  0.899195\n",
      "16    0  1.00  3.00  0.900752\n",
      "17    0  1.00  4.00  0.907817\n",
      "18    0  2.00  0.25  0.910308\n",
      "19    0  2.00  0.50  0.906096\n",
      "20    0  2.00  1.00  0.914685\n",
      "21    0  2.00  2.00  0.900113\n",
      "22    0  2.00  3.00  0.915291\n",
      "23    0  2.00  4.00  0.906194\n",
      "24    0  3.00  0.25  0.911128\n",
      "25    0  3.00  0.50  0.910866\n",
      "26    0  3.00  1.00  0.910767\n",
      "27    0  3.00  2.00  0.908194\n",
      "28    0  3.00  3.00  0.913898\n",
      "29    0  3.00  4.00  0.914718\n",
      "30    0  4.00  0.25  0.908931\n",
      "31    0  4.00  0.50  0.914209\n",
      "32    0  4.00  1.00  0.920340\n",
      "33    0  4.00  2.00  0.917766\n",
      "34    0  4.00  3.00  0.917553\n",
      "35    0  4.00  4.00  0.915996\n",
      "Best combination of p and q: (4.0, 1.0)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import networkx as nx\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Function to load edge list from a file\n",
    "def load_edgelist(file_path):\n",
    "    edges = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            edge = line.strip().split()\n",
    "            edges.append((edge[0], edge[1]))\n",
    "    return edges\n",
    "\n",
    "# Function to sample a subgraph using BFS\n",
    "def sample_subgraph_bfs(graph, start_node=None, number_of_nodes=1000, seed=None):\n",
    "    if start_node is None:\n",
    "        nodes = list(graph.nodes())\n",
    "        random.Random(seed).shuffle(nodes)\n",
    "        start_node = nodes[0]\n",
    "\n",
    "    sampled_nodes = set([start_node])\n",
    "    node_queue = [start_node]\n",
    "\n",
    "    while len(sampled_nodes) < number_of_nodes and node_queue:\n",
    "        current = node_queue.pop(0)\n",
    "        neighbors = sorted(list(graph.neighbors(current)))\n",
    "        random.Random(seed).shuffle(neighbors)\n",
    "\n",
    "        for neighbor in neighbors:\n",
    "            if len(sampled_nodes) >= number_of_nodes:\n",
    "                break\n",
    "            if neighbor not in sampled_nodes:\n",
    "                sampled_nodes.add(neighbor)\n",
    "                node_queue.append(neighbor)\n",
    "\n",
    "    return graph.subgraph(sampled_nodes)\n",
    "\n",
    "# Function to generate edge embeddings\n",
    "def generate_edge_embeddings(edges, embedding_function):\n",
    "    edge_embeddings = []\n",
    "    for u, v in edges:\n",
    "        u_embedding = embedding_function(u)\n",
    "        v_embedding = embedding_function(v)\n",
    "        edge_embedding = np.multiply(u_embedding, v_embedding)\n",
    "        edge_embeddings.append(edge_embedding)\n",
    "    return np.array(edge_embeddings)\n",
    "\n",
    "# Function to split the graph into train and test sets, ensuring connectivity\n",
    "def split_graph_with_connectivity(graph, fraction_to_remove=0.1, seed=None):\n",
    "    edge_list = list(graph.edges())\n",
    "    num_edges_to_remove = int(fraction_to_remove * graph.number_of_edges())\n",
    "\n",
    "    while True:\n",
    "        random.Random(seed).shuffle(edge_list)\n",
    "        edges_to_remove = edge_list[:num_edges_to_remove]\n",
    "        G_train = graph.copy()\n",
    "        G_train.remove_edges_from(edges_to_remove)\n",
    "        if nx.is_connected(G_train):\n",
    "            break\n",
    "\n",
    "    G_test = graph.copy()\n",
    "    G_test.remove_edges_from(G_train.edges())\n",
    "\n",
    "    return G_train, G_test, edges_to_remove\n",
    "\n",
    "# Function to generate positive and negative samples\n",
    "def generate_samples(graph, seed=None):\n",
    "    positive_samples = list(graph.edges())\n",
    "    negative_samples = []\n",
    "    all_nodes = sorted(list(graph.nodes()))\n",
    "\n",
    "    while len(negative_samples) < len(positive_samples):\n",
    "        node_pair = random.sample(all_nodes, 2)\n",
    "        if not graph.has_edge(*node_pair):\n",
    "            negative_samples.append(tuple(sorted(node_pair)))\n",
    "\n",
    "    return positive_samples, negative_samples\n",
    "\n",
    "# Function to generate Node2Vec embeddings\n",
    "def generate_node2vec_embeddings(graph, dimensions=128, num_walks=30, walk_length=5, p=1.0, q=1.0, seed=None):\n",
    "    # Function to perform random walk based on Node2Vec algorithm\n",
    "    def node2vec_walk(node):\n",
    "        walk = [node]\n",
    "        for _ in range(walk_length):\n",
    "            neighbors = list(graph.neighbors(walk[-1]))\n",
    "            if len(neighbors) > 0:\n",
    "                if len(walk) == 1:\n",
    "                    walk.append(random.choice(neighbors))\n",
    "                else:\n",
    "                    prev_node = walk[-2]\n",
    "                    probs = []\n",
    "                    for neighbor in neighbors:\n",
    "                        if neighbor == prev_node:\n",
    "                            probs.append(1 / p)\n",
    "                        elif graph.has_edge(prev_node, neighbor):\n",
    "                            probs.append(1)\n",
    "                        else:\n",
    "                            probs.append(1 / q)\n",
    "                    probs = np.array(probs)\n",
    "                    probs /= np.sum(probs)\n",
    "                    walk.append(np.random.choice(neighbors, p=probs))\n",
    "            else:\n",
    "                break\n",
    "        return walk\n",
    "\n",
    "    # Generating random walks\n",
    "    walks = []\n",
    "    nodes = list(graph.nodes())\n",
    "    for _ in range(num_walks):\n",
    "        random.seed(seed)\n",
    "        random.shuffle(nodes)\n",
    "        for node in nodes:\n",
    "            walks.append(node2vec_walk(node))\n",
    "\n",
    "    # Learning embeddings using Word2Vec with a fixed seed\n",
    "    embeddings = {}\n",
    "    model = Word2Vec(walks, vector_size=dimensions, window=5, min_count=1, sg=1, workers=1, seed=seed)\n",
    "    for node in nodes:\n",
    "        embeddings[node] = model.wv[node]\n",
    "\n",
    "    # Function to get node embeddings\n",
    "    def embedding_function(u):\n",
    "        return embeddings[u]\n",
    "\n",
    "    return model, embedding_function\n",
    "\n",
    "# Grid search over p, q ∈ {0.25, 0.50, 1, 2}\n",
    "p_values = [0.25, 0.5, 1, 2,3,4]\n",
    "q_values = [0.25, 0.5, 1, 2,3,4]\n",
    "\n",
    "# DataFrame to store the results\n",
    "results_df = pd.DataFrame(columns=['seed', 'p', 'q', 'roc_auc'])\n",
    "\n",
    "for seed in range(1):\n",
    "    # Set the new random seed for all functions\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "    # Load the data and create the graph\n",
    "    edge_list = load_edgelist('facebook_combined.txt')  # Replace with your actual file path\n",
    "    G = nx.Graph()\n",
    "    G.add_edges_from(edge_list)\n",
    "\n",
    "    # Sample subgraph, split into train/test, generate samples\n",
    "    subgraph = sample_subgraph_bfs(G, number_of_nodes=300, seed=seed)\n",
    "    G_train, G_test, _ = split_graph_with_connectivity(subgraph, seed=seed)\n",
    "    positive_samples_train, negative_samples_train = generate_samples(G_train, seed=seed)\n",
    "    positive_samples_test, negative_samples_test = generate_samples(G_test, seed=seed)\n",
    "\n",
    "    for p in p_values:\n",
    "        for q in q_values:\n",
    "            # Node2Vec embeddings\n",
    "            _, embedding_function = generate_node2vec_embeddings(G_train, p=p, q=q, seed=seed)\n",
    "\n",
    "            # Generate edge embeddings\n",
    "            edge_embeddings_train = generate_edge_embeddings(positive_samples_train + negative_samples_train, embedding_function)\n",
    "            edge_embeddings_test = generate_edge_embeddings(positive_samples_test + negative_samples_test, embedding_function)\n",
    "\n",
    "            # Logistic Regression Model\n",
    "            labels_train = np.array([1] * len(positive_samples_train) + [0] * len(negative_samples_train))\n",
    "            lr_clf = LogisticRegressionCV(cv=10, max_iter=2000, scoring=\"roc_auc\", random_state=seed)\n",
    "            classifier = lr_clf.fit(edge_embeddings_train, labels_train)\n",
    "\n",
    "            # Evaluate the model\n",
    "            labels_test = np.array([1] * len(positive_samples_test) + [0] * len(negative_samples_test))\n",
    "            test_predictions = classifier.predict_proba(edge_embeddings_test)[:, 1]\n",
    "            test_roc_auc = roc_auc_score(labels_test, test_predictions)\n",
    "\n",
    "            # Store results\n",
    "            results_df = pd.concat([results_df, pd.DataFrame([{'seed': seed, 'p': p, 'q': q, 'roc_auc': test_roc_auc}])], ignore_index=True)\n",
    "\n",
    "# Print DataFrame\n",
    "print(results_df)\n",
    "\n",
    "# Find the best combination of p and q based on average ROC AUC\n",
    "best_combination = results_df.groupby(['p', 'q'])['roc_auc'].mean().idxmax()\n",
    "print(f\"Best combination of p and q: {best_combination}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Walk Length 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ayush\\AppData\\Local\\Temp\\ipykernel_45780\\3199962613.py:178: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_df = pd.concat([results_df, pd.DataFrame([{'seed': seed, 'p': p, 'q': q, 'roc_auc': test_roc_auc}])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   seed     p     q   roc_auc\n",
      "0     0  0.25  0.25  0.907456\n",
      "1     0  0.25  0.50  0.888967\n",
      "2     0  0.25  1.00  0.880395\n",
      "3     0  0.25  2.00  0.883132\n",
      "4     0  0.25  3.00  0.867659\n",
      "5     0  0.25  4.00  0.877657\n",
      "6     0  0.50  0.25  0.899261\n",
      "7     0  0.50  0.50  0.905293\n",
      "8     0  0.50  1.00  0.897556\n",
      "9     0  0.50  2.00  0.892754\n",
      "10    0  0.50  3.00  0.894343\n",
      "11    0  0.50  4.00  0.874281\n",
      "12    0  1.00  0.25  0.900687\n",
      "13    0  1.00  0.50  0.903654\n",
      "14    0  1.00  1.00  0.905194\n",
      "15    0  1.00  2.00  0.898261\n",
      "16    0  1.00  3.00  0.891426\n",
      "17    0  1.00  4.00  0.893852\n",
      "18    0  2.00  0.25  0.891541\n",
      "19    0  2.00  0.50  0.905817\n",
      "20    0  2.00  1.00  0.903719\n",
      "21    0  2.00  2.00  0.892147\n",
      "22    0  2.00  3.00  0.918864\n",
      "23    0  2.00  4.00  0.890688\n",
      "24    0  3.00  0.25  0.902277\n",
      "25    0  3.00  0.50  0.899261\n",
      "26    0  3.00  1.00  0.910046\n",
      "27    0  3.00  2.00  0.907292\n",
      "28    0  3.00  3.00  0.906653\n",
      "29    0  3.00  4.00  0.904965\n",
      "30    0  4.00  0.25  0.907915\n",
      "31    0  4.00  0.50  0.902129\n",
      "32    0  4.00  1.00  0.905358\n",
      "33    0  4.00  2.00  0.889836\n",
      "34    0  4.00  3.00  0.914603\n",
      "35    0  4.00  4.00  0.904227\n",
      "Best combination of p and q: (2.0, 3.0)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import networkx as nx\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Function to load edge list from a file\n",
    "def load_edgelist(file_path):\n",
    "    edges = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            edge = line.strip().split()\n",
    "            edges.append((edge[0], edge[1]))\n",
    "    return edges\n",
    "\n",
    "# Function to sample a subgraph using BFS\n",
    "def sample_subgraph_bfs(graph, start_node=None, number_of_nodes=1000, seed=None):\n",
    "    if start_node is None:\n",
    "        nodes = list(graph.nodes())\n",
    "        random.Random(seed).shuffle(nodes)\n",
    "        start_node = nodes[0]\n",
    "\n",
    "    sampled_nodes = set([start_node])\n",
    "    node_queue = [start_node]\n",
    "\n",
    "    while len(sampled_nodes) < number_of_nodes and node_queue:\n",
    "        current = node_queue.pop(0)\n",
    "        neighbors = sorted(list(graph.neighbors(current)))\n",
    "        random.Random(seed).shuffle(neighbors)\n",
    "\n",
    "        for neighbor in neighbors:\n",
    "            if len(sampled_nodes) >= number_of_nodes:\n",
    "                break\n",
    "            if neighbor not in sampled_nodes:\n",
    "                sampled_nodes.add(neighbor)\n",
    "                node_queue.append(neighbor)\n",
    "\n",
    "    return graph.subgraph(sampled_nodes)\n",
    "\n",
    "# Function to generate edge embeddings\n",
    "def generate_edge_embeddings(edges, embedding_function):\n",
    "    edge_embeddings = []\n",
    "    for u, v in edges:\n",
    "        u_embedding = embedding_function(u)\n",
    "        v_embedding = embedding_function(v)\n",
    "        edge_embedding = np.multiply(u_embedding, v_embedding)\n",
    "        edge_embeddings.append(edge_embedding)\n",
    "    return np.array(edge_embeddings)\n",
    "\n",
    "# Function to split the graph into train and test sets, ensuring connectivity\n",
    "def split_graph_with_connectivity(graph, fraction_to_remove=0.1, seed=None):\n",
    "    edge_list = list(graph.edges())\n",
    "    num_edges_to_remove = int(fraction_to_remove * graph.number_of_edges())\n",
    "\n",
    "    while True:\n",
    "        random.Random(seed).shuffle(edge_list)\n",
    "        edges_to_remove = edge_list[:num_edges_to_remove]\n",
    "        G_train = graph.copy()\n",
    "        G_train.remove_edges_from(edges_to_remove)\n",
    "        if nx.is_connected(G_train):\n",
    "            break\n",
    "\n",
    "    G_test = graph.copy()\n",
    "    G_test.remove_edges_from(G_train.edges())\n",
    "\n",
    "    return G_train, G_test, edges_to_remove\n",
    "\n",
    "# Function to generate positive and negative samples\n",
    "def generate_samples(graph, seed=None):\n",
    "    positive_samples = list(graph.edges())\n",
    "    negative_samples = []\n",
    "    all_nodes = sorted(list(graph.nodes()))\n",
    "\n",
    "    while len(negative_samples) < len(positive_samples):\n",
    "        node_pair = random.sample(all_nodes, 2)\n",
    "        if not graph.has_edge(*node_pair):\n",
    "            negative_samples.append(tuple(sorted(node_pair)))\n",
    "\n",
    "    return positive_samples, negative_samples\n",
    "\n",
    "# Function to generate Node2Vec embeddings\n",
    "def generate_node2vec_embeddings(graph, dimensions=128, num_walks=30, walk_length=15, p=1.0, q=1.0, seed=None):\n",
    "    # Function to perform random walk based on Node2Vec algorithm\n",
    "    def node2vec_walk(node):\n",
    "        walk = [node]\n",
    "        for _ in range(walk_length):\n",
    "            neighbors = list(graph.neighbors(walk[-1]))\n",
    "            if len(neighbors) > 0:\n",
    "                if len(walk) == 1:\n",
    "                    walk.append(random.choice(neighbors))\n",
    "                else:\n",
    "                    prev_node = walk[-2]\n",
    "                    probs = []\n",
    "                    for neighbor in neighbors:\n",
    "                        if neighbor == prev_node:\n",
    "                            probs.append(1 / p)\n",
    "                        elif graph.has_edge(prev_node, neighbor):\n",
    "                            probs.append(1)\n",
    "                        else:\n",
    "                            probs.append(1 / q)\n",
    "                    probs = np.array(probs)\n",
    "                    probs /= np.sum(probs)\n",
    "                    walk.append(np.random.choice(neighbors, p=probs))\n",
    "            else:\n",
    "                break\n",
    "        return walk\n",
    "\n",
    "    # Generating random walks\n",
    "    walks = []\n",
    "    nodes = list(graph.nodes())\n",
    "    for _ in range(num_walks):\n",
    "        random.seed(seed)\n",
    "        random.shuffle(nodes)\n",
    "        for node in nodes:\n",
    "            walks.append(node2vec_walk(node))\n",
    "\n",
    "    # Learning embeddings using Word2Vec with a fixed seed\n",
    "    embeddings = {}\n",
    "    model = Word2Vec(walks, vector_size=dimensions, window=5, min_count=1, sg=1, workers=1, seed=seed)\n",
    "    for node in nodes:\n",
    "        embeddings[node] = model.wv[node]\n",
    "\n",
    "    # Function to get node embeddings\n",
    "    def embedding_function(u):\n",
    "        return embeddings[u]\n",
    "\n",
    "    return model, embedding_function\n",
    "\n",
    "# Grid search over p, q ∈ {0.25, 0.50, 1, 2}\n",
    "p_values = [0.25, 0.5, 1, 2,3,4]\n",
    "q_values = [0.25, 0.5, 1, 2,3,4]\n",
    "\n",
    "# DataFrame to store the results\n",
    "results_df = pd.DataFrame(columns=['seed', 'p', 'q', 'roc_auc'])\n",
    "\n",
    "for seed in range(1):\n",
    "    # Set the new random seed for all functions\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "    # Load the data and create the graph\n",
    "    edge_list = load_edgelist('facebook_combined.txt')  # Replace with your actual file path\n",
    "    G = nx.Graph()\n",
    "    G.add_edges_from(edge_list)\n",
    "\n",
    "    # Sample subgraph, split into train/test, generate samples\n",
    "    subgraph = sample_subgraph_bfs(G, number_of_nodes=300, seed=seed)\n",
    "    G_train, G_test, _ = split_graph_with_connectivity(subgraph, seed=seed)\n",
    "    positive_samples_train, negative_samples_train = generate_samples(G_train, seed=seed)\n",
    "    positive_samples_test, negative_samples_test = generate_samples(G_test, seed=seed)\n",
    "\n",
    "    for p in p_values:\n",
    "        for q in q_values:\n",
    "            # Node2Vec embeddings\n",
    "            _, embedding_function = generate_node2vec_embeddings(G_train, p=p, q=q, seed=seed)\n",
    "\n",
    "            # Generate edge embeddings\n",
    "            edge_embeddings_train = generate_edge_embeddings(positive_samples_train + negative_samples_train, embedding_function)\n",
    "            edge_embeddings_test = generate_edge_embeddings(positive_samples_test + negative_samples_test, embedding_function)\n",
    "\n",
    "            # Logistic Regression Model\n",
    "            labels_train = np.array([1] * len(positive_samples_train) + [0] * len(negative_samples_train))\n",
    "            lr_clf = LogisticRegressionCV(cv=10, max_iter=2000, scoring=\"roc_auc\", random_state=seed)\n",
    "            classifier = lr_clf.fit(edge_embeddings_train, labels_train)\n",
    "\n",
    "            # Evaluate the model\n",
    "            labels_test = np.array([1] * len(positive_samples_test) + [0] * len(negative_samples_test))\n",
    "            test_predictions = classifier.predict_proba(edge_embeddings_test)[:, 1]\n",
    "            test_roc_auc = roc_auc_score(labels_test, test_predictions)\n",
    "\n",
    "            # Store results\n",
    "            results_df = pd.concat([results_df, pd.DataFrame([{'seed': seed, 'p': p, 'q': q, 'roc_auc': test_roc_auc}])], ignore_index=True)\n",
    "\n",
    "# Print DataFrame\n",
    "print(results_df)\n",
    "\n",
    "# Find the best combination of p and q based on average ROC AUC\n",
    "best_combination = results_df.groupby(['p', 'q'])['roc_auc'].mean().idxmax()\n",
    "print(f\"Best combination of p and q: {best_combination}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi Scale walks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ayush\\AppData\\Local\\Temp\\ipykernel_45780\\3406144043.py:178: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_df = pd.concat([results_df, pd.DataFrame([{'seed': seed, 'p': p, 'q': q, 'roc_auc': test_roc_auc}])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   seed     p     q   roc_auc\n",
      "0     0  0.25  0.25  0.908735\n",
      "1     0  0.25  0.50  0.898785\n",
      "2     0  0.25  1.00  0.890000\n",
      "3     0  0.25  2.00  0.898589\n",
      "4     0  0.25  3.00  0.877526\n",
      "5     0  0.25  4.00  0.874199\n",
      "6     0  0.50  0.25  0.911587\n",
      "7     0  0.50  0.50  0.914341\n",
      "8     0  0.50  1.00  0.896458\n",
      "9     0  0.50  2.00  0.904113\n",
      "10    0  0.50  3.00  0.893032\n",
      "11    0  0.50  4.00  0.904506\n",
      "12    0  1.00  0.25  0.910800\n",
      "13    0  1.00  0.50  0.906735\n",
      "14    0  1.00  1.00  0.915062\n",
      "15    0  1.00  2.00  0.906653\n",
      "16    0  1.00  3.00  0.895638\n",
      "17    0  1.00  4.00  0.880477\n",
      "18    0  2.00  0.25  0.910964\n",
      "19    0  2.00  0.50  0.911472\n",
      "20    0  2.00  1.00  0.919864\n",
      "21    0  2.00  2.00  0.911423\n",
      "22    0  2.00  3.00  0.914636\n",
      "23    0  2.00  4.00  0.891098\n",
      "24    0  3.00  0.25  0.902867\n",
      "25    0  3.00  0.50  0.910948\n",
      "26    0  3.00  1.00  0.906047\n",
      "27    0  3.00  2.00  0.911685\n",
      "28    0  3.00  3.00  0.907637\n",
      "29    0  3.00  4.00  0.904539\n",
      "30    0  4.00  0.25  0.914963\n",
      "31    0  4.00  0.50  0.921208\n",
      "32    0  4.00  1.00  0.906063\n",
      "33    0  4.00  2.00  0.911111\n",
      "34    0  4.00  3.00  0.906030\n",
      "35    0  4.00  4.00  0.908276\n",
      "Best combination of p and q: (4.0, 0.5)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import networkx as nx\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Function to load edge list from a file\n",
    "def load_edgelist(file_path):\n",
    "    edges = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            edge = line.strip().split()\n",
    "            edges.append((edge[0], edge[1]))\n",
    "    return edges\n",
    "\n",
    "# Function to sample a subgraph using BFS\n",
    "def sample_subgraph_bfs(graph, start_node=None, number_of_nodes=1000, seed=None):\n",
    "    if start_node is None:\n",
    "        nodes = list(graph.nodes())\n",
    "        random.Random(seed).shuffle(nodes)\n",
    "        start_node = nodes[0]\n",
    "\n",
    "    sampled_nodes = set([start_node])\n",
    "    node_queue = [start_node]\n",
    "\n",
    "    while len(sampled_nodes) < number_of_nodes and node_queue:\n",
    "        current = node_queue.pop(0)\n",
    "        neighbors = sorted(list(graph.neighbors(current)))\n",
    "        random.Random(seed).shuffle(neighbors)\n",
    "\n",
    "        for neighbor in neighbors:\n",
    "            if len(sampled_nodes) >= number_of_nodes:\n",
    "                break\n",
    "            if neighbor not in sampled_nodes:\n",
    "                sampled_nodes.add(neighbor)\n",
    "                node_queue.append(neighbor)\n",
    "\n",
    "    return graph.subgraph(sampled_nodes)\n",
    "\n",
    "# Function to generate edge embeddings\n",
    "def generate_edge_embeddings(edges, embedding_function):\n",
    "    edge_embeddings = []\n",
    "    for u, v in edges:\n",
    "        u_embedding = embedding_function(u)\n",
    "        v_embedding = embedding_function(v)\n",
    "        edge_embedding = np.multiply(u_embedding, v_embedding)\n",
    "        edge_embeddings.append(edge_embedding)\n",
    "    return np.array(edge_embeddings)\n",
    "\n",
    "# Function to split the graph into train and test sets, ensuring connectivity\n",
    "def split_graph_with_connectivity(graph, fraction_to_remove=0.1, seed=None):\n",
    "    edge_list = list(graph.edges())\n",
    "    num_edges_to_remove = int(fraction_to_remove * graph.number_of_edges())\n",
    "\n",
    "    while True:\n",
    "        random.Random(seed).shuffle(edge_list)\n",
    "        edges_to_remove = edge_list[:num_edges_to_remove]\n",
    "        G_train = graph.copy()\n",
    "        G_train.remove_edges_from(edges_to_remove)\n",
    "        if nx.is_connected(G_train):\n",
    "            break\n",
    "\n",
    "    G_test = graph.copy()\n",
    "    G_test.remove_edges_from(G_train.edges())\n",
    "\n",
    "    return G_train, G_test, edges_to_remove\n",
    "\n",
    "# Function to generate positive and negative samples\n",
    "def generate_samples(graph, seed=None):\n",
    "    positive_samples = list(graph.edges())\n",
    "    negative_samples = []\n",
    "    all_nodes = sorted(list(graph.nodes()))\n",
    "\n",
    "    while len(negative_samples) < len(positive_samples):\n",
    "        node_pair = random.sample(all_nodes, 2)\n",
    "        if not graph.has_edge(*node_pair):\n",
    "            negative_samples.append(tuple(sorted(node_pair)))\n",
    "\n",
    "    return positive_samples, negative_samples\n",
    "\n",
    "def generate_node2vec_embeddings_multiscale(graph, dimensions=128, num_walks=10, walk_lengths=[5, 10, 15], p=1.0, q=1.0, seed=None):\n",
    "    def node2vec_walk(node, length):\n",
    "        walk = [node]\n",
    "        for _ in range(length):\n",
    "            neighbors = list(graph.neighbors(walk[-1]))\n",
    "            if len(neighbors) > 0:\n",
    "                if len(walk) == 1:\n",
    "                    walk.append(random.choice(neighbors))\n",
    "                else:\n",
    "                    prev_node = walk[-2]\n",
    "                    probs = []\n",
    "                    for neighbor in neighbors:\n",
    "                        if neighbor == prev_node:\n",
    "                            probs.append(1 / p)\n",
    "                        elif graph.has_edge(prev_node, neighbor):\n",
    "                            probs.append(1)\n",
    "                        else:\n",
    "                            probs.append(1 / q)\n",
    "                    probs = np.array(probs)\n",
    "                    probs /= np.sum(probs)\n",
    "                    walk.append(np.random.choice(neighbors, p=probs))\n",
    "            else:\n",
    "                break\n",
    "        return walk\n",
    "\n",
    "    walks = []\n",
    "    nodes = list(graph.nodes())\n",
    "    for _ in range(num_walks):\n",
    "        random.seed(seed)\n",
    "        random.shuffle(nodes)\n",
    "        for node in nodes:\n",
    "            for length in walk_lengths:\n",
    "                walks.append(node2vec_walk(node, length))\n",
    "\n",
    "    embeddings = {}\n",
    "    model = Word2Vec(walks, vector_size=dimensions, window=5, min_count=1, sg=1, workers=1, seed=seed)\n",
    "    for node in nodes:\n",
    "        embeddings[node] = model.wv[node]\n",
    "\n",
    "    def embedding_function(u):\n",
    "        return embeddings[u]\n",
    "\n",
    "    return model, embedding_function\n",
    "\n",
    "\n",
    "# Grid search over p, q ∈ {0.25, 0.50, 1, 2}\n",
    "p_values = [0.25, 0.5, 1, 2,3,4]\n",
    "q_values = [0.25, 0.5, 1, 2,3,4]\n",
    "\n",
    "# DataFrame to store the results\n",
    "results_df = pd.DataFrame(columns=['seed', 'p', 'q', 'roc_auc'])\n",
    "\n",
    "for seed in range(1):\n",
    "    # Set the new random seed for all functions\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "    # Load the data and create the graph\n",
    "    edge_list = load_edgelist('facebook_combined.txt')# Replace with your actual file path\n",
    "    G = nx.Graph()\n",
    "    G.add_edges_from(edge_list)\n",
    "\n",
    "    # Sample subgraph, split into train/test, generate samples\n",
    "    subgraph = sample_subgraph_bfs(G, number_of_nodes=300, seed=seed)\n",
    "    G_train, G_test, _ = split_graph_with_connectivity(subgraph, seed=seed)\n",
    "    positive_samples_train, negative_samples_train = generate_samples(G_train, seed=seed)\n",
    "    positive_samples_test, negative_samples_test = generate_samples(G_test, seed=seed)\n",
    "\n",
    "    # Define the list of walk lengths for multi-scale sampling\n",
    "    walk_lengths = [5, 10, 15]  # Adjust this list based on the lengths you want to explore\n",
    "\n",
    "    for p in p_values:\n",
    "        for q in q_values:\n",
    "            # Node2Vec embeddings with multi-scale sampling\n",
    "            _, embedding_function = generate_node2vec_embeddings_multiscale(G_train, p=p, q=q, walk_lengths=walk_lengths, seed=seed)\n",
    "\n",
    "            # Generate edge embeddings\n",
    "            edge_embeddings_train = generate_edge_embeddings(positive_samples_train + negative_samples_train, embedding_function)\n",
    "            edge_embeddings_test = generate_edge_embeddings(positive_samples_test + negative_samples_test, embedding_function)\n",
    "\n",
    "            # Logistic Regression Model\n",
    "            labels_train = np.array([1] * len(positive_samples_train) + [0] * len(negative_samples_train))\n",
    "            lr_clf = LogisticRegressionCV(cv=10, max_iter=2000, scoring=\"roc_auc\", random_state=seed)\n",
    "            classifier = lr_clf.fit(edge_embeddings_train, labels_train)\n",
    "\n",
    "            # Evaluate the model\n",
    "            labels_test = np.array([1] * len(positive_samples_test) + [0] * len(negative_samples_test))\n",
    "            test_predictions = classifier.predict_proba(edge_embeddings_test)[:, 1]\n",
    "            test_roc_auc = roc_auc_score(labels_test, test_predictions)\n",
    "\n",
    "            # Store results\n",
    "            results_df = pd.concat([results_df, pd.DataFrame([{'seed': seed, 'p': p, 'q': q, 'roc_auc': test_roc_auc}])], ignore_index=True)\n",
    "\n",
    "# Print DataFrame\n",
    "print(results_df)\n",
    "\n",
    "# Find the best combination of p and q based on average ROC AUC\n",
    "best_combination = results_df.groupby(['p', 'q'])['roc_auc'].mean().idxmax()\n",
    "print(f\"Best combination of p and q: {best_combination}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
