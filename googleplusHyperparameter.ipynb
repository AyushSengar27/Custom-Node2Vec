{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Walk Length 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ayush\\AppData\\Local\\Temp\\ipykernel_38572\\4259806221.py:179: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_df = pd.concat([results_df, pd.DataFrame([{'seed': seed, 'p': p, 'q': q, 'roc_auc': test_roc_auc}])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   seed     p     q   roc_auc\n",
      "0     0  0.25  0.25  0.922388\n",
      "1     0  0.25  0.50  0.925014\n",
      "2     0  0.25  1.00  0.914294\n",
      "3     0  0.25  2.00  0.912074\n",
      "4     0  0.50  0.25  0.922596\n",
      "5     0  0.50  0.50  0.919881\n",
      "6     0  0.50  1.00  0.930306\n",
      "7     0  0.50  2.00  0.929529\n",
      "8     0  1.00  0.25  0.935148\n",
      "9     0  1.00  0.50  0.930390\n",
      "10    0  1.00  1.00  0.930619\n",
      "11    0  1.00  2.00  0.926846\n",
      "12    0  2.00  0.25  0.918795\n",
      "13    0  2.00  0.50  0.925504\n",
      "14    0  2.00  1.00  0.930200\n",
      "15    0  2.00  2.00  0.929573\n",
      "Best combination of p and q: (1.0, 0.25)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import networkx as nx\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Function to load edge list from a file\n",
    "def load_edgelist(file_path):\n",
    "    edges = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            edge = line.strip().split()\n",
    "            edges.append((edge[0], edge[1]))\n",
    "    return edges\n",
    "\n",
    "# Function to sample a subgraph using BFS\n",
    "def sample_subgraph_bfs(graph, start_node=None, number_of_nodes=1000, seed=None):\n",
    "    if start_node is None:\n",
    "        nodes = list(graph.nodes())\n",
    "        random.Random(seed).shuffle(nodes)\n",
    "        start_node = nodes[0]\n",
    "\n",
    "    sampled_nodes = set([start_node])\n",
    "    node_queue = [start_node]\n",
    "\n",
    "    while len(sampled_nodes) < number_of_nodes and node_queue:\n",
    "        current = node_queue.pop(0)\n",
    "        neighbors = sorted(list(graph.neighbors(current)))\n",
    "        random.Random(seed).shuffle(neighbors)\n",
    "\n",
    "        for neighbor in neighbors:\n",
    "            if len(sampled_nodes) >= number_of_nodes:\n",
    "                break\n",
    "            if neighbor not in sampled_nodes:\n",
    "                sampled_nodes.add(neighbor)\n",
    "                node_queue.append(neighbor)\n",
    "\n",
    "    return graph.subgraph(sampled_nodes)\n",
    "\n",
    "# Function to generate edge embeddings\n",
    "def generate_edge_embeddings(edges, embedding_function):\n",
    "    edge_embeddings = []\n",
    "    for u, v in edges:\n",
    "        u_embedding = embedding_function(u)\n",
    "        v_embedding = embedding_function(v)\n",
    "        edge_embedding = np.multiply(u_embedding, v_embedding)\n",
    "        edge_embeddings.append(edge_embedding)\n",
    "    return np.array(edge_embeddings)\n",
    "\n",
    "# Function to split the graph into train and test sets, ensuring connectivity\n",
    "def split_graph_with_connectivity(graph, fraction_to_remove=0.1, seed=None):\n",
    "    edge_list = list(graph.edges())\n",
    "    num_edges_to_remove = int(fraction_to_remove * graph.number_of_edges())\n",
    "\n",
    "    while True:\n",
    "        random.Random(seed).shuffle(edge_list)\n",
    "        edges_to_remove = edge_list[:num_edges_to_remove]\n",
    "        G_train = graph.copy()\n",
    "        G_train.remove_edges_from(edges_to_remove)\n",
    "        if nx.is_connected(G_train):\n",
    "            break\n",
    "\n",
    "    G_test = graph.copy()\n",
    "    G_test.remove_edges_from(G_train.edges())\n",
    "\n",
    "    return G_train, G_test, edges_to_remove\n",
    "\n",
    "# Function to generate positive and negative samples\n",
    "def generate_samples(graph, seed=None):\n",
    "    positive_samples = list(graph.edges())\n",
    "    negative_samples = []\n",
    "    all_nodes = sorted(list(graph.nodes()))\n",
    "\n",
    "    while len(negative_samples) < len(positive_samples):\n",
    "        node_pair = random.sample(all_nodes, 2)\n",
    "        if not graph.has_edge(*node_pair):\n",
    "            negative_samples.append(tuple(sorted(node_pair)))\n",
    "\n",
    "    return positive_samples, negative_samples\n",
    "\n",
    "# Function to generate Node2Vec embeddings\n",
    "def generate_node2vec_embeddings(graph, dimensions=128, num_walks=30, walk_length=10, p=1.0, q=1.0, seed=None):\n",
    "    # Function to perform random walk based on Node2Vec algorithm\n",
    "    def node2vec_walk(node):\n",
    "        walk = [node]\n",
    "        for _ in range(walk_length):\n",
    "            neighbors = list(graph.neighbors(walk[-1]))\n",
    "            if len(neighbors) > 0:\n",
    "                if len(walk) == 1:\n",
    "                    walk.append(random.choice(neighbors))\n",
    "                else:\n",
    "                    prev_node = walk[-2]\n",
    "                    probs = []\n",
    "                    for neighbor in neighbors:\n",
    "                        if neighbor == prev_node:\n",
    "                            probs.append(1 / p)\n",
    "                        elif graph.has_edge(prev_node, neighbor):\n",
    "                            probs.append(1)\n",
    "                        else:\n",
    "                            probs.append(1 / q)\n",
    "                    probs = np.array(probs)\n",
    "                    probs /= np.sum(probs)\n",
    "                    walk.append(np.random.choice(neighbors, p=probs))\n",
    "            else:\n",
    "                break\n",
    "        return walk\n",
    "\n",
    "    # Generating random walks\n",
    "    walks = []\n",
    "    nodes = list(graph.nodes())\n",
    "    for _ in range(num_walks):\n",
    "        random.seed(seed)\n",
    "        random.shuffle(nodes)\n",
    "        for node in nodes:\n",
    "            walks.append(node2vec_walk(node))\n",
    "\n",
    "    # Learning embeddings using Word2Vec with a fixed seed\n",
    "    embeddings = {}\n",
    "    model = Word2Vec(walks, vector_size=dimensions, window=5, min_count=1, sg=1, workers=1, seed=seed)\n",
    "    for node in nodes:\n",
    "        embeddings[node] = model.wv[node]\n",
    "\n",
    "    # Function to get node embeddings\n",
    "    def embedding_function(u):\n",
    "        return embeddings[u]\n",
    "\n",
    "    return model, embedding_function\n",
    "\n",
    "# Grid search over p, q âˆˆ {0.25, 0.50, 1, 2}\n",
    "p_values = [0.25, 0.5, 1, 2]\n",
    "q_values = [0.25, 0.5, 1, 2]\n",
    "\n",
    "# DataFrame to store the results\n",
    "results_df = pd.DataFrame(columns=['seed', 'p', 'q', 'roc_auc'])\n",
    "\n",
    "for seed in range(1):\n",
    "    # Set the new random seed for all functions\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "    # Load the data and create the graph\n",
    "    edge_list = load_edgelist('googleplus.txt')\n",
    " # Replace with your actual file path\n",
    "    G = nx.Graph()\n",
    "    G.add_edges_from(edge_list)\n",
    "\n",
    "    # Sample subgraph, split into train/test, generate samples\n",
    "    subgraph = sample_subgraph_bfs(G, number_of_nodes=300, seed=seed)\n",
    "    G_train, G_test, _ = split_graph_with_connectivity(subgraph, seed=seed)\n",
    "    positive_samples_train, negative_samples_train = generate_samples(G_train, seed=seed)\n",
    "    positive_samples_test, negative_samples_test = generate_samples(G_test, seed=seed)\n",
    "\n",
    "    for p in p_values:\n",
    "        for q in q_values:\n",
    "            # Node2Vec embeddings\n",
    "            _, embedding_function = generate_node2vec_embeddings(G_train, p=p, q=q, seed=seed)\n",
    "\n",
    "            # Generate edge embeddings\n",
    "            edge_embeddings_train = generate_edge_embeddings(positive_samples_train + negative_samples_train, embedding_function)\n",
    "            edge_embeddings_test = generate_edge_embeddings(positive_samples_test + negative_samples_test, embedding_function)\n",
    "\n",
    "            # Logistic Regression Model\n",
    "            labels_train = np.array([1] * len(positive_samples_train) + [0] * len(negative_samples_train))\n",
    "            lr_clf = LogisticRegressionCV(cv=10, max_iter=2000, scoring=\"roc_auc\", random_state=seed)\n",
    "            classifier = lr_clf.fit(edge_embeddings_train, labels_train)\n",
    "\n",
    "            # Evaluate the model\n",
    "            labels_test = np.array([1] * len(positive_samples_test) + [0] * len(negative_samples_test))\n",
    "            test_predictions = classifier.predict_proba(edge_embeddings_test)[:, 1]\n",
    "            test_roc_auc = roc_auc_score(labels_test, test_predictions)\n",
    "\n",
    "            # Store results\n",
    "            results_df = pd.concat([results_df, pd.DataFrame([{'seed': seed, 'p': p, 'q': q, 'roc_auc': test_roc_auc}])], ignore_index=True)\n",
    "\n",
    "# Print DataFrame\n",
    "print(results_df)\n",
    "\n",
    "# Find the best combination of p and q based on average ROC AUC\n",
    "best_combination = results_df.groupby(['p', 'q'])['roc_auc'].mean().idxmax()\n",
    "print(f\"Best combination of p and q: {best_combination}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Walk Length 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ayush\\AppData\\Local\\Temp\\ipykernel_38572\\790407908.py:179: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_df = pd.concat([results_df, pd.DataFrame([{'seed': seed, 'p': p, 'q': q, 'roc_auc': test_roc_auc}])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   seed     p     q   roc_auc\n",
      "0     0  0.25  0.25  0.897465\n",
      "1     0  0.25  0.50  0.895152\n",
      "2     0  0.25  1.00  0.892169\n",
      "3     0  0.25  2.00  0.885028\n",
      "4     0  0.50  0.25  0.906468\n",
      "5     0  0.50  0.50  0.911050\n",
      "6     0  0.50  1.00  0.904915\n",
      "7     0  0.50  2.00  0.913270\n",
      "8     0  1.00  0.25  0.910582\n",
      "9     0  1.00  0.50  0.918725\n",
      "10    0  1.00  1.00  0.906835\n",
      "11    0  1.00  2.00  0.919338\n",
      "12    0  2.00  0.25  0.911332\n",
      "13    0  2.00  0.50  0.924449\n",
      "14    0  2.00  1.00  0.918107\n",
      "15    0  2.00  2.00  0.926938\n",
      "Best combination of p and q: (2.0, 2.0)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import networkx as nx\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Function to load edge list from a file\n",
    "def load_edgelist(file_path):\n",
    "    edges = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            edge = line.strip().split()\n",
    "            edges.append((edge[0], edge[1]))\n",
    "    return edges\n",
    "\n",
    "# Function to sample a subgraph using BFS\n",
    "def sample_subgraph_bfs(graph, start_node=None, number_of_nodes=1000, seed=None):\n",
    "    if start_node is None:\n",
    "        nodes = list(graph.nodes())\n",
    "        random.Random(seed).shuffle(nodes)\n",
    "        start_node = nodes[0]\n",
    "\n",
    "    sampled_nodes = set([start_node])\n",
    "    node_queue = [start_node]\n",
    "\n",
    "    while len(sampled_nodes) < number_of_nodes and node_queue:\n",
    "        current = node_queue.pop(0)\n",
    "        neighbors = sorted(list(graph.neighbors(current)))\n",
    "        random.Random(seed).shuffle(neighbors)\n",
    "\n",
    "        for neighbor in neighbors:\n",
    "            if len(sampled_nodes) >= number_of_nodes:\n",
    "                break\n",
    "            if neighbor not in sampled_nodes:\n",
    "                sampled_nodes.add(neighbor)\n",
    "                node_queue.append(neighbor)\n",
    "\n",
    "    return graph.subgraph(sampled_nodes)\n",
    "\n",
    "# Function to generate edge embeddings\n",
    "def generate_edge_embeddings(edges, embedding_function):\n",
    "    edge_embeddings = []\n",
    "    for u, v in edges:\n",
    "        u_embedding = embedding_function(u)\n",
    "        v_embedding = embedding_function(v)\n",
    "        edge_embedding = np.multiply(u_embedding, v_embedding)\n",
    "        edge_embeddings.append(edge_embedding)\n",
    "    return np.array(edge_embeddings)\n",
    "\n",
    "# Function to split the graph into train and test sets, ensuring connectivity\n",
    "def split_graph_with_connectivity(graph, fraction_to_remove=0.1, seed=None):\n",
    "    edge_list = list(graph.edges())\n",
    "    num_edges_to_remove = int(fraction_to_remove * graph.number_of_edges())\n",
    "\n",
    "    while True:\n",
    "        random.Random(seed).shuffle(edge_list)\n",
    "        edges_to_remove = edge_list[:num_edges_to_remove]\n",
    "        G_train = graph.copy()\n",
    "        G_train.remove_edges_from(edges_to_remove)\n",
    "        if nx.is_connected(G_train):\n",
    "            break\n",
    "\n",
    "    G_test = graph.copy()\n",
    "    G_test.remove_edges_from(G_train.edges())\n",
    "\n",
    "    return G_train, G_test, edges_to_remove\n",
    "\n",
    "# Function to generate positive and negative samples\n",
    "def generate_samples(graph, seed=None):\n",
    "    positive_samples = list(graph.edges())\n",
    "    negative_samples = []\n",
    "    all_nodes = sorted(list(graph.nodes()))\n",
    "\n",
    "    while len(negative_samples) < len(positive_samples):\n",
    "        node_pair = random.sample(all_nodes, 2)\n",
    "        if not graph.has_edge(*node_pair):\n",
    "            negative_samples.append(tuple(sorted(node_pair)))\n",
    "\n",
    "    return positive_samples, negative_samples\n",
    "\n",
    "# Function to generate Node2Vec embeddings\n",
    "def generate_node2vec_embeddings(graph, dimensions=128, num_walks=30, walk_length=15, p=1.0, q=1.0, seed=None):\n",
    "    # Function to perform random walk based on Node2Vec algorithm\n",
    "    def node2vec_walk(node):\n",
    "        walk = [node]\n",
    "        for _ in range(walk_length):\n",
    "            neighbors = list(graph.neighbors(walk[-1]))\n",
    "            if len(neighbors) > 0:\n",
    "                if len(walk) == 1:\n",
    "                    walk.append(random.choice(neighbors))\n",
    "                else:\n",
    "                    prev_node = walk[-2]\n",
    "                    probs = []\n",
    "                    for neighbor in neighbors:\n",
    "                        if neighbor == prev_node:\n",
    "                            probs.append(1 / p)\n",
    "                        elif graph.has_edge(prev_node, neighbor):\n",
    "                            probs.append(1)\n",
    "                        else:\n",
    "                            probs.append(1 / q)\n",
    "                    probs = np.array(probs)\n",
    "                    probs /= np.sum(probs)\n",
    "                    walk.append(np.random.choice(neighbors, p=probs))\n",
    "            else:\n",
    "                break\n",
    "        return walk\n",
    "\n",
    "    # Generating random walks\n",
    "    walks = []\n",
    "    nodes = list(graph.nodes())\n",
    "    for _ in range(num_walks):\n",
    "        random.seed(seed)\n",
    "        random.shuffle(nodes)\n",
    "        for node in nodes:\n",
    "            walks.append(node2vec_walk(node))\n",
    "\n",
    "    # Learning embeddings using Word2Vec with a fixed seed\n",
    "    embeddings = {}\n",
    "    model = Word2Vec(walks, vector_size=dimensions, window=5, min_count=1, sg=1, workers=1, seed=seed)\n",
    "    for node in nodes:\n",
    "        embeddings[node] = model.wv[node]\n",
    "\n",
    "    # Function to get node embeddings\n",
    "    def embedding_function(u):\n",
    "        return embeddings[u]\n",
    "\n",
    "    return model, embedding_function\n",
    "\n",
    "# Grid search over p, q âˆˆ {0.25, 0.50, 1, 2}\n",
    "p_values = [0.25, 0.5, 1, 2]\n",
    "q_values = [0.25, 0.5, 1, 2]\n",
    "\n",
    "# DataFrame to store the results\n",
    "results_df = pd.DataFrame(columns=['seed', 'p', 'q', 'roc_auc'])\n",
    "\n",
    "for seed in range(1):\n",
    "    # Set the new random seed for all functions\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "    # Load the data and create the graph\n",
    "    edge_list = load_edgelist('googleplus.txt')\n",
    " # Replace with your actual file path\n",
    "    G = nx.Graph()\n",
    "    G.add_edges_from(edge_list)\n",
    "\n",
    "    # Sample subgraph, split into train/test, generate samples\n",
    "    subgraph = sample_subgraph_bfs(G, number_of_nodes=300, seed=seed)\n",
    "    G_train, G_test, _ = split_graph_with_connectivity(subgraph, seed=seed)\n",
    "    positive_samples_train, negative_samples_train = generate_samples(G_train, seed=seed)\n",
    "    positive_samples_test, negative_samples_test = generate_samples(G_test, seed=seed)\n",
    "\n",
    "    for p in p_values:\n",
    "        for q in q_values:\n",
    "            # Node2Vec embeddings\n",
    "            _, embedding_function = generate_node2vec_embeddings(G_train, p=p, q=q, seed=seed)\n",
    "\n",
    "            # Generate edge embeddings\n",
    "            edge_embeddings_train = generate_edge_embeddings(positive_samples_train + negative_samples_train, embedding_function)\n",
    "            edge_embeddings_test = generate_edge_embeddings(positive_samples_test + negative_samples_test, embedding_function)\n",
    "\n",
    "            # Logistic Regression Model\n",
    "            labels_train = np.array([1] * len(positive_samples_train) + [0] * len(negative_samples_train))\n",
    "            lr_clf = LogisticRegressionCV(cv=10, max_iter=2000, scoring=\"roc_auc\", random_state=seed)\n",
    "            classifier = lr_clf.fit(edge_embeddings_train, labels_train)\n",
    "\n",
    "            # Evaluate the model\n",
    "            labels_test = np.array([1] * len(positive_samples_test) + [0] * len(negative_samples_test))\n",
    "            test_predictions = classifier.predict_proba(edge_embeddings_test)[:, 1]\n",
    "            test_roc_auc = roc_auc_score(labels_test, test_predictions)\n",
    "\n",
    "            # Store results\n",
    "            results_df = pd.concat([results_df, pd.DataFrame([{'seed': seed, 'p': p, 'q': q, 'roc_auc': test_roc_auc}])], ignore_index=True)\n",
    "\n",
    "# Print DataFrame\n",
    "print(results_df)\n",
    "\n",
    "# Find the best combination of p and q based on average ROC AUC\n",
    "best_combination = results_df.groupby(['p', 'q'])['roc_auc'].mean().idxmax()\n",
    "print(f\"Best combination of p and q: {best_combination}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Walk Length 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ayush\\AppData\\Local\\Temp\\ipykernel_38572\\904782512.py:179: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_df = pd.concat([results_df, pd.DataFrame([{'seed': seed, 'p': p, 'q': q, 'roc_auc': test_roc_auc}])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   seed     p     q   roc_auc\n",
      "0     0  0.25  0.25  0.925071\n",
      "1     0  0.25  0.50  0.929225\n",
      "2     0  0.25  1.00  0.923443\n",
      "3     0  0.25  2.00  0.916712\n",
      "4     0  0.50  0.25  0.928545\n",
      "5     0  0.50  0.50  0.925001\n",
      "6     0  0.50  1.00  0.919965\n",
      "7     0  0.50  2.00  0.932018\n",
      "8     0  1.00  0.25  0.917427\n",
      "9     0  1.00  0.50  0.927561\n",
      "10    0  1.00  1.00  0.928655\n",
      "11    0  1.00  2.00  0.928854\n",
      "12    0  2.00  0.25  0.930134\n",
      "13    0  2.00  0.50  0.935130\n",
      "14    0  2.00  1.00  0.933969\n",
      "15    0  2.00  2.00  0.928541\n",
      "Best combination of p and q: (2.0, 0.5)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import networkx as nx\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Function to load edge list from a file\n",
    "def load_edgelist(file_path):\n",
    "    edges = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            edge = line.strip().split()\n",
    "            edges.append((edge[0], edge[1]))\n",
    "    return edges\n",
    "\n",
    "# Function to sample a subgraph using BFS\n",
    "def sample_subgraph_bfs(graph, start_node=None, number_of_nodes=1000, seed=None):\n",
    "    if start_node is None:\n",
    "        nodes = list(graph.nodes())\n",
    "        random.Random(seed).shuffle(nodes)\n",
    "        start_node = nodes[0]\n",
    "\n",
    "    sampled_nodes = set([start_node])\n",
    "    node_queue = [start_node]\n",
    "\n",
    "    while len(sampled_nodes) < number_of_nodes and node_queue:\n",
    "        current = node_queue.pop(0)\n",
    "        neighbors = sorted(list(graph.neighbors(current)))\n",
    "        random.Random(seed).shuffle(neighbors)\n",
    "\n",
    "        for neighbor in neighbors:\n",
    "            if len(sampled_nodes) >= number_of_nodes:\n",
    "                break\n",
    "            if neighbor not in sampled_nodes:\n",
    "                sampled_nodes.add(neighbor)\n",
    "                node_queue.append(neighbor)\n",
    "\n",
    "    return graph.subgraph(sampled_nodes)\n",
    "\n",
    "# Function to generate edge embeddings\n",
    "def generate_edge_embeddings(edges, embedding_function):\n",
    "    edge_embeddings = []\n",
    "    for u, v in edges:\n",
    "        u_embedding = embedding_function(u)\n",
    "        v_embedding = embedding_function(v)\n",
    "        edge_embedding = np.multiply(u_embedding, v_embedding)\n",
    "        edge_embeddings.append(edge_embedding)\n",
    "    return np.array(edge_embeddings)\n",
    "\n",
    "# Function to split the graph into train and test sets, ensuring connectivity\n",
    "def split_graph_with_connectivity(graph, fraction_to_remove=0.1, seed=None):\n",
    "    edge_list = list(graph.edges())\n",
    "    num_edges_to_remove = int(fraction_to_remove * graph.number_of_edges())\n",
    "\n",
    "    while True:\n",
    "        random.Random(seed).shuffle(edge_list)\n",
    "        edges_to_remove = edge_list[:num_edges_to_remove]\n",
    "        G_train = graph.copy()\n",
    "        G_train.remove_edges_from(edges_to_remove)\n",
    "        if nx.is_connected(G_train):\n",
    "            break\n",
    "\n",
    "    G_test = graph.copy()\n",
    "    G_test.remove_edges_from(G_train.edges())\n",
    "\n",
    "    return G_train, G_test, edges_to_remove\n",
    "\n",
    "# Function to generate positive and negative samples\n",
    "def generate_samples(graph, seed=None):\n",
    "    positive_samples = list(graph.edges())\n",
    "    negative_samples = []\n",
    "    all_nodes = sorted(list(graph.nodes()))\n",
    "\n",
    "    while len(negative_samples) < len(positive_samples):\n",
    "        node_pair = random.sample(all_nodes, 2)\n",
    "        if not graph.has_edge(*node_pair):\n",
    "            negative_samples.append(tuple(sorted(node_pair)))\n",
    "\n",
    "    return positive_samples, negative_samples\n",
    "\n",
    "# Function to generate Node2Vec embeddings\n",
    "def generate_node2vec_embeddings(graph, dimensions=128, num_walks=30, walk_length=5, p=1.0, q=1.0, seed=None):\n",
    "    # Function to perform random walk based on Node2Vec algorithm\n",
    "    def node2vec_walk(node):\n",
    "        walk = [node]\n",
    "        for _ in range(walk_length):\n",
    "            neighbors = list(graph.neighbors(walk[-1]))\n",
    "            if len(neighbors) > 0:\n",
    "                if len(walk) == 1:\n",
    "                    walk.append(random.choice(neighbors))\n",
    "                else:\n",
    "                    prev_node = walk[-2]\n",
    "                    probs = []\n",
    "                    for neighbor in neighbors:\n",
    "                        if neighbor == prev_node:\n",
    "                            probs.append(1 / p)\n",
    "                        elif graph.has_edge(prev_node, neighbor):\n",
    "                            probs.append(1)\n",
    "                        else:\n",
    "                            probs.append(1 / q)\n",
    "                    probs = np.array(probs)\n",
    "                    probs /= np.sum(probs)\n",
    "                    walk.append(np.random.choice(neighbors, p=probs))\n",
    "            else:\n",
    "                break\n",
    "        return walk\n",
    "\n",
    "    # Generating random walks\n",
    "    walks = []\n",
    "    nodes = list(graph.nodes())\n",
    "    for _ in range(num_walks):\n",
    "        random.seed(seed)\n",
    "        random.shuffle(nodes)\n",
    "        for node in nodes:\n",
    "            walks.append(node2vec_walk(node))\n",
    "\n",
    "    # Learning embeddings using Word2Vec with a fixed seed\n",
    "    embeddings = {}\n",
    "    model = Word2Vec(walks, vector_size=dimensions, window=5, min_count=1, sg=1, workers=1, seed=seed)\n",
    "    for node in nodes:\n",
    "        embeddings[node] = model.wv[node]\n",
    "\n",
    "    # Function to get node embeddings\n",
    "    def embedding_function(u):\n",
    "        return embeddings[u]\n",
    "\n",
    "    return model, embedding_function\n",
    "\n",
    "# Grid search over p, q âˆˆ {0.25, 0.50, 1, 2}\n",
    "p_values = [0.25, 0.5, 1, 2]\n",
    "q_values = [0.25, 0.5, 1, 2]\n",
    "\n",
    "# DataFrame to store the results\n",
    "results_df = pd.DataFrame(columns=['seed', 'p', 'q', 'roc_auc'])\n",
    "\n",
    "for seed in range(1):\n",
    "    # Set the new random seed for all functions\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "    # Load the data and create the graph\n",
    "    edge_list = load_edgelist('googleplus.txt')\n",
    " # Replace with your actual file path\n",
    "    G = nx.Graph()\n",
    "    G.add_edges_from(edge_list)\n",
    "\n",
    "    # Sample subgraph, split into train/test, generate samples\n",
    "    subgraph = sample_subgraph_bfs(G, number_of_nodes=300, seed=seed)\n",
    "    G_train, G_test, _ = split_graph_with_connectivity(subgraph, seed=seed)\n",
    "    positive_samples_train, negative_samples_train = generate_samples(G_train, seed=seed)\n",
    "    positive_samples_test, negative_samples_test = generate_samples(G_test, seed=seed)\n",
    "\n",
    "    for p in p_values:\n",
    "        for q in q_values:\n",
    "            # Node2Vec embeddings\n",
    "            _, embedding_function = generate_node2vec_embeddings(G_train, p=p, q=q, seed=seed)\n",
    "\n",
    "            # Generate edge embeddings\n",
    "            edge_embeddings_train = generate_edge_embeddings(positive_samples_train + negative_samples_train, embedding_function)\n",
    "            edge_embeddings_test = generate_edge_embeddings(positive_samples_test + negative_samples_test, embedding_function)\n",
    "\n",
    "            # Logistic Regression Model\n",
    "            labels_train = np.array([1] * len(positive_samples_train) + [0] * len(negative_samples_train))\n",
    "            lr_clf = LogisticRegressionCV(cv=10, max_iter=2000, scoring=\"roc_auc\", random_state=seed)\n",
    "            classifier = lr_clf.fit(edge_embeddings_train, labels_train)\n",
    "\n",
    "            # Evaluate the model\n",
    "            labels_test = np.array([1] * len(positive_samples_test) + [0] * len(negative_samples_test))\n",
    "            test_predictions = classifier.predict_proba(edge_embeddings_test)[:, 1]\n",
    "            test_roc_auc = roc_auc_score(labels_test, test_predictions)\n",
    "\n",
    "            # Store results\n",
    "            results_df = pd.concat([results_df, pd.DataFrame([{'seed': seed, 'p': p, 'q': q, 'roc_auc': test_roc_auc}])], ignore_index=True)\n",
    "\n",
    "# Print DataFrame\n",
    "print(results_df)\n",
    "\n",
    "# Find the best combination of p and q based on average ROC AUC\n",
    "best_combination = results_df.groupby(['p', 'q'])['roc_auc'].mean().idxmax()\n",
    "print(f\"Best combination of p and q: {best_combination}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi Scale walk length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ayush\\AppData\\Local\\Temp\\ipykernel_38572\\2133609023.py:179: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_df = pd.concat([results_df, pd.DataFrame([{'seed': seed, 'p': p, 'q': q, 'roc_auc': test_roc_auc}])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   seed     p     q   roc_auc\n",
      "0     0  0.25  0.25  0.926903\n",
      "1     0  0.25  0.50  0.920367\n",
      "2     0  0.25  1.00  0.910017\n",
      "3     0  0.25  2.00  0.908777\n",
      "4     0  0.50  0.25  0.920689\n",
      "5     0  0.50  0.50  0.923143\n",
      "6     0  0.50  1.00  0.926435\n",
      "7     0  0.50  2.00  0.923946\n",
      "8     0  1.00  0.25  0.926960\n",
      "9     0  1.00  0.50  0.930650\n",
      "10    0  1.00  1.00  0.926515\n",
      "11    0  1.00  2.00  0.926846\n",
      "12    0  2.00  0.25  0.928042\n",
      "13    0  2.00  0.50  0.934190\n",
      "14    0  2.00  1.00  0.924921\n",
      "15    0  2.00  2.00  0.923231\n",
      "Best combination of p and q: (2.0, 0.5)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import networkx as nx\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Function to load edge list from a file\n",
    "def load_edgelist(file_path):\n",
    "    edges = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            edge = line.strip().split()\n",
    "            edges.append((edge[0], edge[1]))\n",
    "    return edges\n",
    "\n",
    "# Function to sample a subgraph using BFS\n",
    "def sample_subgraph_bfs(graph, start_node=None, number_of_nodes=1000, seed=None):\n",
    "    if start_node is None:\n",
    "        nodes = list(graph.nodes())\n",
    "        random.Random(seed).shuffle(nodes)\n",
    "        start_node = nodes[0]\n",
    "\n",
    "    sampled_nodes = set([start_node])\n",
    "    node_queue = [start_node]\n",
    "\n",
    "    while len(sampled_nodes) < number_of_nodes and node_queue:\n",
    "        current = node_queue.pop(0)\n",
    "        neighbors = sorted(list(graph.neighbors(current)))\n",
    "        random.Random(seed).shuffle(neighbors)\n",
    "\n",
    "        for neighbor in neighbors:\n",
    "            if len(sampled_nodes) >= number_of_nodes:\n",
    "                break\n",
    "            if neighbor not in sampled_nodes:\n",
    "                sampled_nodes.add(neighbor)\n",
    "                node_queue.append(neighbor)\n",
    "\n",
    "    return graph.subgraph(sampled_nodes)\n",
    "\n",
    "# Function to generate edge embeddings\n",
    "def generate_edge_embeddings(edges, embedding_function):\n",
    "    edge_embeddings = []\n",
    "    for u, v in edges:\n",
    "        u_embedding = embedding_function(u)\n",
    "        v_embedding = embedding_function(v)\n",
    "        edge_embedding = np.multiply(u_embedding, v_embedding)\n",
    "        edge_embeddings.append(edge_embedding)\n",
    "    return np.array(edge_embeddings)\n",
    "\n",
    "# Function to split the graph into train and test sets, ensuring connectivity\n",
    "def split_graph_with_connectivity(graph, fraction_to_remove=0.1, seed=None):\n",
    "    edge_list = list(graph.edges())\n",
    "    num_edges_to_remove = int(fraction_to_remove * graph.number_of_edges())\n",
    "\n",
    "    while True:\n",
    "        random.Random(seed).shuffle(edge_list)\n",
    "        edges_to_remove = edge_list[:num_edges_to_remove]\n",
    "        G_train = graph.copy()\n",
    "        G_train.remove_edges_from(edges_to_remove)\n",
    "        if nx.is_connected(G_train):\n",
    "            break\n",
    "\n",
    "    G_test = graph.copy()\n",
    "    G_test.remove_edges_from(G_train.edges())\n",
    "\n",
    "    return G_train, G_test, edges_to_remove\n",
    "\n",
    "# Function to generate positive and negative samples\n",
    "def generate_samples(graph, seed=None):\n",
    "    positive_samples = list(graph.edges())\n",
    "    negative_samples = []\n",
    "    all_nodes = sorted(list(graph.nodes()))\n",
    "\n",
    "    while len(negative_samples) < len(positive_samples):\n",
    "        node_pair = random.sample(all_nodes, 2)\n",
    "        if not graph.has_edge(*node_pair):\n",
    "            negative_samples.append(tuple(sorted(node_pair)))\n",
    "\n",
    "    return positive_samples, negative_samples\n",
    "\n",
    "def generate_node2vec_embeddings_multiscale(graph, dimensions=128, num_walks=10, walk_lengths=[5, 10, 15], p=1.0, q=1.0, seed=None):\n",
    "    def node2vec_walk(node, length):\n",
    "        walk = [node]\n",
    "        for _ in range(length):\n",
    "            neighbors = list(graph.neighbors(walk[-1]))\n",
    "            if len(neighbors) > 0:\n",
    "                if len(walk) == 1:\n",
    "                    walk.append(random.choice(neighbors))\n",
    "                else:\n",
    "                    prev_node = walk[-2]\n",
    "                    probs = []\n",
    "                    for neighbor in neighbors:\n",
    "                        if neighbor == prev_node:\n",
    "                            probs.append(1 / p)\n",
    "                        elif graph.has_edge(prev_node, neighbor):\n",
    "                            probs.append(1)\n",
    "                        else:\n",
    "                            probs.append(1 / q)\n",
    "                    probs = np.array(probs)\n",
    "                    probs /= np.sum(probs)\n",
    "                    walk.append(np.random.choice(neighbors, p=probs))\n",
    "            else:\n",
    "                break\n",
    "        return walk\n",
    "\n",
    "    walks = []\n",
    "    nodes = list(graph.nodes())\n",
    "    for _ in range(num_walks):\n",
    "        random.seed(seed)\n",
    "        random.shuffle(nodes)\n",
    "        for node in nodes:\n",
    "            for length in walk_lengths:\n",
    "                walks.append(node2vec_walk(node, length))\n",
    "\n",
    "    embeddings = {}\n",
    "    model = Word2Vec(walks, vector_size=dimensions, window=5, min_count=1, sg=1, workers=1, seed=seed)\n",
    "    for node in nodes:\n",
    "        embeddings[node] = model.wv[node]\n",
    "\n",
    "    def embedding_function(u):\n",
    "        return embeddings[u]\n",
    "\n",
    "    return model, embedding_function\n",
    "\n",
    "\n",
    "# Grid search over p, q âˆˆ {0.25, 0.50, 1, 2}\n",
    "p_values = [0.25, 0.5, 1, 2]\n",
    "q_values = [0.25, 0.5, 1, 2]\n",
    "\n",
    "# DataFrame to store the results\n",
    "results_df = pd.DataFrame(columns=['seed', 'p', 'q', 'roc_auc'])\n",
    "\n",
    "for seed in range(1):\n",
    "    # Set the new random seed for all functions\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "    # Load the data and create the graph\n",
    "    edge_list = load_edgelist('googleplus.txt')\n",
    "# Replace with your actual file path\n",
    "    G = nx.Graph()\n",
    "    G.add_edges_from(edge_list)\n",
    "\n",
    "    # Sample subgraph, split into train/test, generate samples\n",
    "    subgraph = sample_subgraph_bfs(G, number_of_nodes=300, seed=seed)\n",
    "    G_train, G_test, _ = split_graph_with_connectivity(subgraph, seed=seed)\n",
    "    positive_samples_train, negative_samples_train = generate_samples(G_train, seed=seed)\n",
    "    positive_samples_test, negative_samples_test = generate_samples(G_test, seed=seed)\n",
    "\n",
    "    # Define the list of walk lengths for multi-scale sampling\n",
    "    walk_lengths = [5, 10, 15]  # Adjust this list based on the lengths you want to explore\n",
    "\n",
    "    for p in p_values:\n",
    "        for q in q_values:\n",
    "            # Node2Vec embeddings with multi-scale sampling\n",
    "            _, embedding_function = generate_node2vec_embeddings_multiscale(G_train, p=p, q=q, walk_lengths=walk_lengths, seed=seed)\n",
    "\n",
    "            # Generate edge embeddings\n",
    "            edge_embeddings_train = generate_edge_embeddings(positive_samples_train + negative_samples_train, embedding_function)\n",
    "            edge_embeddings_test = generate_edge_embeddings(positive_samples_test + negative_samples_test, embedding_function)\n",
    "\n",
    "            # Logistic Regression Model\n",
    "            labels_train = np.array([1] * len(positive_samples_train) + [0] * len(negative_samples_train))\n",
    "            lr_clf = LogisticRegressionCV(cv=10, max_iter=2000, scoring=\"roc_auc\", random_state=seed)\n",
    "            classifier = lr_clf.fit(edge_embeddings_train, labels_train)\n",
    "\n",
    "            # Evaluate the model\n",
    "            labels_test = np.array([1] * len(positive_samples_test) + [0] * len(negative_samples_test))\n",
    "            test_predictions = classifier.predict_proba(edge_embeddings_test)[:, 1]\n",
    "            test_roc_auc = roc_auc_score(labels_test, test_predictions)\n",
    "\n",
    "            # Store results\n",
    "            results_df = pd.concat([results_df, pd.DataFrame([{'seed': seed, 'p': p, 'q': q, 'roc_auc': test_roc_auc}])], ignore_index=True)\n",
    "\n",
    "# Print DataFrame\n",
    "print(results_df)\n",
    "\n",
    "# Find the best combination of p and q based on average ROC AUC\n",
    "best_combination = results_df.groupby(['p', 'q'])['roc_auc'].mean().idxmax()\n",
    "print(f\"Best combination of p and q: {best_combination}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
