{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All walks of len 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ayush\\AppData\\Local\\Temp\\ipykernel_7320\\1050575353.py:178: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_df = pd.concat([results_df, pd.DataFrame([{'seed': seed, 'p': p, 'q': q, 'roc_auc': test_roc_auc}])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   seed     p     q   roc_auc\n",
      "0    45  0.25  0.25  0.769878\n",
      "1    45  0.25  0.50  0.782082\n",
      "2    45  0.25  1.00  0.769601\n",
      "3    45  0.25  2.00  0.785873\n",
      "4    45  0.50  0.25  0.765717\n",
      "5    45  0.50  0.50  0.768861\n",
      "6    45  0.50  1.00  0.750185\n",
      "7    45  0.50  2.00  0.753328\n",
      "8    45  1.00  0.25  0.771080\n",
      "9    45  1.00  0.50  0.764608\n",
      "10   45  1.00  1.00  0.759893\n",
      "11   45  1.00  2.00  0.775148\n",
      "12   45  2.00  0.25  0.774408\n",
      "13   45  2.00  0.50  0.797522\n",
      "14   45  2.00  1.00  0.718935\n",
      "15   45  2.00  2.00  0.740477\n",
      "Best combination of p and q: (2.0, 0.5)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import networkx as nx\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Function to load edge list from a file\n",
    "def load_edgelist(file_path):\n",
    "    edges = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            edge = line.strip().split()\n",
    "            edges.append((edge[0], edge[1]))\n",
    "    return edges\n",
    "\n",
    "# Function to sample a subgraph using BFS\n",
    "def sample_subgraph_bfs(graph, start_node=None, number_of_nodes=1000, seed=None):\n",
    "    if start_node is None:\n",
    "        nodes = list(graph.nodes())\n",
    "        random.Random(seed).shuffle(nodes)\n",
    "        start_node = nodes[0]\n",
    "\n",
    "    sampled_nodes = set([start_node])\n",
    "    node_queue = [start_node]\n",
    "\n",
    "    while len(sampled_nodes) < number_of_nodes and node_queue:\n",
    "        current = node_queue.pop(0)\n",
    "        neighbors = sorted(list(graph.neighbors(current)))\n",
    "        random.Random(seed).shuffle(neighbors)\n",
    "\n",
    "        for neighbor in neighbors:\n",
    "            if len(sampled_nodes) >= number_of_nodes:\n",
    "                break\n",
    "            if neighbor not in sampled_nodes:\n",
    "                sampled_nodes.add(neighbor)\n",
    "                node_queue.append(neighbor)\n",
    "\n",
    "    return graph.subgraph(sampled_nodes)\n",
    "\n",
    "# Function to generate edge embeddings\n",
    "def generate_edge_embeddings(edges, embedding_function):\n",
    "    edge_embeddings = []\n",
    "    for u, v in edges:\n",
    "        u_embedding = embedding_function(u)\n",
    "        v_embedding = embedding_function(v)\n",
    "        edge_embedding = np.multiply(u_embedding, v_embedding)\n",
    "        edge_embeddings.append(edge_embedding)\n",
    "    return np.array(edge_embeddings)\n",
    "\n",
    "# Function to split the graph into train and test sets, ensuring connectivity\n",
    "def split_graph_with_connectivity(graph, fraction_to_remove=0.1, seed=None):\n",
    "    edge_list = list(graph.edges())\n",
    "    num_edges_to_remove = int(fraction_to_remove * graph.number_of_edges())\n",
    "\n",
    "    while True:\n",
    "        random.Random(seed).shuffle(edge_list)\n",
    "        edges_to_remove = edge_list[:num_edges_to_remove]\n",
    "        G_train = graph.copy()\n",
    "        G_train.remove_edges_from(edges_to_remove)\n",
    "        if nx.is_connected(G_train):\n",
    "            break\n",
    "\n",
    "    G_test = graph.copy()\n",
    "    G_test.remove_edges_from(G_train.edges())\n",
    "\n",
    "    return G_train, G_test, edges_to_remove\n",
    "\n",
    "# Function to generate positive and negative samples\n",
    "def generate_samples(graph, seed=None):\n",
    "    positive_samples = list(graph.edges())\n",
    "    negative_samples = []\n",
    "    all_nodes = sorted(list(graph.nodes()))\n",
    "\n",
    "    while len(negative_samples) < len(positive_samples):\n",
    "        node_pair = random.sample(all_nodes, 2)\n",
    "        if not graph.has_edge(*node_pair):\n",
    "            negative_samples.append(tuple(sorted(node_pair)))\n",
    "\n",
    "    return positive_samples, negative_samples\n",
    "\n",
    "# Function to generate Node2Vec embeddings\n",
    "def generate_node2vec_embeddings(graph, dimensions=128, num_walks=10, walk_length=10, p=1.0, q=1.0, seed=None):\n",
    "    # Function to perform random walk based on Node2Vec algorithm\n",
    "    def node2vec_walk(node):\n",
    "        walk = [node]\n",
    "        for _ in range(walk_length):\n",
    "            neighbors = list(graph.neighbors(walk[-1]))\n",
    "            if len(neighbors) > 0:\n",
    "                if len(walk) == 1:\n",
    "                    walk.append(random.choice(neighbors))\n",
    "                else:\n",
    "                    prev_node = walk[-2]\n",
    "                    probs = []\n",
    "                    for neighbor in neighbors:\n",
    "                        if neighbor == prev_node:\n",
    "                            probs.append(1 / p)\n",
    "                        elif graph.has_edge(prev_node, neighbor):\n",
    "                            probs.append(1)\n",
    "                        else:\n",
    "                            probs.append(1 / q)\n",
    "                    probs = np.array(probs)\n",
    "                    probs /= np.sum(probs)\n",
    "                    walk.append(np.random.choice(neighbors, p=probs))\n",
    "            else:\n",
    "                break\n",
    "        return walk\n",
    "\n",
    "    # Generating random walks\n",
    "    walks = []\n",
    "    nodes = list(graph.nodes())\n",
    "    for _ in range(num_walks):\n",
    "        random.seed(seed)\n",
    "        random.shuffle(nodes)\n",
    "        for node in nodes:\n",
    "            walks.append(node2vec_walk(node))\n",
    "\n",
    "    # Learning embeddings using Word2Vec with a fixed seed\n",
    "    embeddings = {}\n",
    "    model = Word2Vec(walks, vector_size=dimensions, window=5, min_count=1, sg=1, workers=1, seed=seed)\n",
    "    for node in nodes:\n",
    "        embeddings[node] = model.wv[node]\n",
    "\n",
    "    # Function to get node embeddings\n",
    "    def embedding_function(u):\n",
    "        return embeddings[u]\n",
    "\n",
    "    return model, embedding_function\n",
    "\n",
    "# Grid search over p, q ∈ {0.25, 0.50, 1, 2}\n",
    "p_values = [0.25, 0.5, 1, 2]\n",
    "q_values = [0.25, 0.5, 1, 2]\n",
    "\n",
    "# DataFrame to store the results\n",
    "results_df = pd.DataFrame(columns=['seed', 'p', 'q', 'roc_auc'])\n",
    "\n",
    "for seed in range(45,46):\n",
    "    # Set the new random seed for all functions\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "    # Load the data and create the graph\n",
    "    edge_list = load_edgelist('wiki.txt') # Replace with your actual file path\n",
    "    G = nx.Graph()\n",
    "    G.add_edges_from(edge_list)\n",
    "\n",
    "    # Sample subgraph, split into train/test, generate samples\n",
    "    subgraph = sample_subgraph_bfs(G, number_of_nodes=300, seed=seed)\n",
    "    G_train, G_test, _ = split_graph_with_connectivity(subgraph, seed=seed)\n",
    "    positive_samples_train, negative_samples_train = generate_samples(G_train, seed=seed)\n",
    "    positive_samples_test, negative_samples_test = generate_samples(G_test, seed=seed)\n",
    "\n",
    "    for p in p_values:\n",
    "        for q in q_values:\n",
    "            # Node2Vec embeddings\n",
    "            _, embedding_function = generate_node2vec_embeddings(G_train, p=p, q=q, seed=seed)\n",
    "\n",
    "            # Generate edge embeddings\n",
    "            edge_embeddings_train = generate_edge_embeddings(positive_samples_train + negative_samples_train, embedding_function)\n",
    "            edge_embeddings_test = generate_edge_embeddings(positive_samples_test + negative_samples_test, embedding_function)\n",
    "\n",
    "            # Logistic Regression Model\n",
    "            labels_train = np.array([1] * len(positive_samples_train) + [0] * len(negative_samples_train))\n",
    "            lr_clf = LogisticRegressionCV(cv=10, max_iter=2000, scoring=\"roc_auc\", random_state=seed)\n",
    "            classifier = lr_clf.fit(edge_embeddings_train, labels_train)\n",
    "\n",
    "            # Evaluate the model\n",
    "            labels_test = np.array([1] * len(positive_samples_test) + [0] * len(negative_samples_test))\n",
    "            test_predictions = classifier.predict_proba(edge_embeddings_test)[:, 1]\n",
    "            test_roc_auc = roc_auc_score(labels_test, test_predictions)\n",
    "\n",
    "            # Store results\n",
    "            results_df = pd.concat([results_df, pd.DataFrame([{'seed': seed, 'p': p, 'q': q, 'roc_auc': test_roc_auc}])], ignore_index=True)\n",
    "\n",
    "# Print DataFrame\n",
    "print(results_df)\n",
    "\n",
    "# Find the best combination of p and q based on average ROC AUC\n",
    "best_combination = results_df.groupby(['p', 'q'])['roc_auc'].mean().idxmax()\n",
    "print(f\"Best combination of p and q: {best_combination}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best combination of p and q len 10: (2.0, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All walks of len 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ayush\\AppData\\Local\\Temp\\ipykernel_7320\\2977417938.py:178: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_df = pd.concat([results_df, pd.DataFrame([{'seed': seed, 'p': p, 'q': q, 'roc_auc': test_roc_auc}])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   seed     p     q   roc_auc\n",
      "0    45  0.25  0.25  0.751757\n",
      "1    45  0.25  0.50  0.759061\n",
      "2    45  0.25  1.00  0.731324\n",
      "3    45  0.25  2.00  0.743343\n",
      "4    45  0.50  0.25  0.772282\n",
      "5    45  0.50  0.50  0.772097\n",
      "6    45  0.50  1.00  0.791882\n",
      "7    45  0.50  2.00  0.747966\n",
      "8    45  1.00  0.25  0.768491\n",
      "9    45  1.00  0.50  0.783192\n",
      "10   45  1.00  1.00  0.774778\n",
      "11   45  1.00  2.00  0.786797\n",
      "12   45  2.00  0.25  0.744638\n",
      "13   45  2.00  0.50  0.813794\n",
      "14   45  2.00  1.00  0.792899\n",
      "15   45  2.00  2.00  0.780880\n",
      "Best combination of p and q: (2.0, 0.5)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import networkx as nx\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Function to load edge list from a file\n",
    "def load_edgelist(file_path):\n",
    "    edges = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            edge = line.strip().split()\n",
    "            edges.append((edge[0], edge[1]))\n",
    "    return edges\n",
    "\n",
    "# Function to sample a subgraph using BFS\n",
    "def sample_subgraph_bfs(graph, start_node=None, number_of_nodes=1000, seed=None):\n",
    "    if start_node is None:\n",
    "        nodes = list(graph.nodes())\n",
    "        random.Random(seed).shuffle(nodes)\n",
    "        start_node = nodes[0]\n",
    "\n",
    "    sampled_nodes = set([start_node])\n",
    "    node_queue = [start_node]\n",
    "\n",
    "    while len(sampled_nodes) < number_of_nodes and node_queue:\n",
    "        current = node_queue.pop(0)\n",
    "        neighbors = sorted(list(graph.neighbors(current)))\n",
    "        random.Random(seed).shuffle(neighbors)\n",
    "\n",
    "        for neighbor in neighbors:\n",
    "            if len(sampled_nodes) >= number_of_nodes:\n",
    "                break\n",
    "            if neighbor not in sampled_nodes:\n",
    "                sampled_nodes.add(neighbor)\n",
    "                node_queue.append(neighbor)\n",
    "\n",
    "    return graph.subgraph(sampled_nodes)\n",
    "\n",
    "# Function to generate edge embeddings\n",
    "def generate_edge_embeddings(edges, embedding_function):\n",
    "    edge_embeddings = []\n",
    "    for u, v in edges:\n",
    "        u_embedding = embedding_function(u)\n",
    "        v_embedding = embedding_function(v)\n",
    "        edge_embedding = np.multiply(u_embedding, v_embedding)\n",
    "        edge_embeddings.append(edge_embedding)\n",
    "    return np.array(edge_embeddings)\n",
    "\n",
    "# Function to split the graph into train and test sets, ensuring connectivity\n",
    "def split_graph_with_connectivity(graph, fraction_to_remove=0.1, seed=None):\n",
    "    edge_list = list(graph.edges())\n",
    "    num_edges_to_remove = int(fraction_to_remove * graph.number_of_edges())\n",
    "\n",
    "    while True:\n",
    "        random.Random(seed).shuffle(edge_list)\n",
    "        edges_to_remove = edge_list[:num_edges_to_remove]\n",
    "        G_train = graph.copy()\n",
    "        G_train.remove_edges_from(edges_to_remove)\n",
    "        if nx.is_connected(G_train):\n",
    "            break\n",
    "\n",
    "    G_test = graph.copy()\n",
    "    G_test.remove_edges_from(G_train.edges())\n",
    "\n",
    "    return G_train, G_test, edges_to_remove\n",
    "\n",
    "# Function to generate positive and negative samples\n",
    "def generate_samples(graph, seed=None):\n",
    "    positive_samples = list(graph.edges())\n",
    "    negative_samples = []\n",
    "    all_nodes = sorted(list(graph.nodes()))\n",
    "\n",
    "    while len(negative_samples) < len(positive_samples):\n",
    "        node_pair = random.sample(all_nodes, 2)\n",
    "        if not graph.has_edge(*node_pair):\n",
    "            negative_samples.append(tuple(sorted(node_pair)))\n",
    "\n",
    "    return positive_samples, negative_samples\n",
    "\n",
    "# Function to generate Node2Vec embeddings\n",
    "def generate_node2vec_embeddings(graph, dimensions=128, num_walks=10, walk_length=15, p=1.0, q=1.0, seed=None):\n",
    "    # Function to perform random walk based on Node2Vec algorithm\n",
    "    def node2vec_walk(node):\n",
    "        walk = [node]\n",
    "        for _ in range(walk_length):\n",
    "            neighbors = list(graph.neighbors(walk[-1]))\n",
    "            if len(neighbors) > 0:\n",
    "                if len(walk) == 1:\n",
    "                    walk.append(random.choice(neighbors))\n",
    "                else:\n",
    "                    prev_node = walk[-2]\n",
    "                    probs = []\n",
    "                    for neighbor in neighbors:\n",
    "                        if neighbor == prev_node:\n",
    "                            probs.append(1 / p)\n",
    "                        elif graph.has_edge(prev_node, neighbor):\n",
    "                            probs.append(1)\n",
    "                        else:\n",
    "                            probs.append(1 / q)\n",
    "                    probs = np.array(probs)\n",
    "                    probs /= np.sum(probs)\n",
    "                    walk.append(np.random.choice(neighbors, p=probs))\n",
    "            else:\n",
    "                break\n",
    "        return walk\n",
    "\n",
    "    # Generating random walks\n",
    "    walks = []\n",
    "    nodes = list(graph.nodes())\n",
    "    for _ in range(num_walks):\n",
    "        random.seed(seed)\n",
    "        random.shuffle(nodes)\n",
    "        for node in nodes:\n",
    "            walks.append(node2vec_walk(node))\n",
    "\n",
    "    # Learning embeddings using Word2Vec with a fixed seed\n",
    "    embeddings = {}\n",
    "    model = Word2Vec(walks, vector_size=dimensions, window=5, min_count=1, sg=1, workers=1, seed=seed)\n",
    "    for node in nodes:\n",
    "        embeddings[node] = model.wv[node]\n",
    "\n",
    "    # Function to get node embeddings\n",
    "    def embedding_function(u):\n",
    "        return embeddings[u]\n",
    "\n",
    "    return model, embedding_function\n",
    "\n",
    "# Grid search over p, q ∈ {0.25, 0.50, 1, 2}\n",
    "p_values = [0.25, 0.5, 1, 2]\n",
    "q_values = [0.25, 0.5, 1, 2]\n",
    "\n",
    "# DataFrame to store the results\n",
    "results_df = pd.DataFrame(columns=['seed', 'p', 'q', 'roc_auc'])\n",
    "\n",
    "for seed in range(45,46):\n",
    "    # Set the new random seed for all functions\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "    # Load the data and create the graph\n",
    "    edge_list = load_edgelist('wiki.txt') # Replace with your actual file path\n",
    "    G = nx.Graph()\n",
    "    G.add_edges_from(edge_list)\n",
    "\n",
    "    # Sample subgraph, split into train/test, generate samples\n",
    "    subgraph = sample_subgraph_bfs(G, number_of_nodes=300, seed=seed)\n",
    "    G_train, G_test, _ = split_graph_with_connectivity(subgraph, seed=seed)\n",
    "    positive_samples_train, negative_samples_train = generate_samples(G_train, seed=seed)\n",
    "    positive_samples_test, negative_samples_test = generate_samples(G_test, seed=seed)\n",
    "\n",
    "    for p in p_values:\n",
    "        for q in q_values:\n",
    "            # Node2Vec embeddings\n",
    "            _, embedding_function = generate_node2vec_embeddings(G_train, p=p, q=q, seed=seed)\n",
    "\n",
    "            # Generate edge embeddings\n",
    "            edge_embeddings_train = generate_edge_embeddings(positive_samples_train + negative_samples_train, embedding_function)\n",
    "            edge_embeddings_test = generate_edge_embeddings(positive_samples_test + negative_samples_test, embedding_function)\n",
    "\n",
    "            # Logistic Regression Model\n",
    "            labels_train = np.array([1] * len(positive_samples_train) + [0] * len(negative_samples_train))\n",
    "            lr_clf = LogisticRegressionCV(cv=10, max_iter=2000, scoring=\"roc_auc\", random_state=seed)\n",
    "            classifier = lr_clf.fit(edge_embeddings_train, labels_train)\n",
    "\n",
    "            # Evaluate the model\n",
    "            labels_test = np.array([1] * len(positive_samples_test) + [0] * len(negative_samples_test))\n",
    "            test_predictions = classifier.predict_proba(edge_embeddings_test)[:, 1]\n",
    "            test_roc_auc = roc_auc_score(labels_test, test_predictions)\n",
    "\n",
    "            # Store results\n",
    "            results_df = pd.concat([results_df, pd.DataFrame([{'seed': seed, 'p': p, 'q': q, 'roc_auc': test_roc_auc}])], ignore_index=True)\n",
    "\n",
    "# Print DataFrame\n",
    "print(results_df)\n",
    "\n",
    "# Find the best combination of p and q based on average ROC AUC\n",
    "best_combination = results_df.groupby(['p', 'q'])['roc_auc'].mean().idxmax()\n",
    "print(f\"Best combination of p and q: {best_combination}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best combination of p and q len 15: (2.0, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All walks of len 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ayush\\AppData\\Local\\Temp\\ipykernel_7320\\4014757574.py:178: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_df = pd.concat([results_df, pd.DataFrame([{'seed': seed, 'p': p, 'q': q, 'roc_auc': test_roc_auc}])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   seed     p     q   roc_auc\n",
      "0    45  0.25  0.25  0.813702\n",
      "1    45  0.25  0.50  0.762666\n",
      "2    45  0.25  1.00  0.760170\n",
      "3    45  0.25  2.00  0.795766\n",
      "4    45  0.50  0.25  0.767012\n",
      "5    45  0.50  0.50  0.766827\n",
      "6    45  0.50  1.00  0.786705\n",
      "7    45  0.50  2.00  0.807045\n",
      "8    45  1.00  0.25  0.799186\n",
      "9    45  1.00  0.50  0.803162\n",
      "10   45  1.00  1.00  0.781990\n",
      "11   45  1.00  2.00  0.771542\n",
      "12   45  2.00  0.25  0.786797\n",
      "13   45  2.00  0.50  0.795396\n",
      "14   45  2.00  1.00  0.762112\n",
      "15   45  2.00  2.00  0.782082\n",
      "Best combination of p and q: (0.25, 0.25)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import networkx as nx\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Function to load edge list from a file\n",
    "def load_edgelist(file_path):\n",
    "    edges = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            edge = line.strip().split()\n",
    "            edges.append((edge[0], edge[1]))\n",
    "    return edges\n",
    "\n",
    "# Function to sample a subgraph using BFS\n",
    "def sample_subgraph_bfs(graph, start_node=None, number_of_nodes=1000, seed=None):\n",
    "    if start_node is None:\n",
    "        nodes = list(graph.nodes())\n",
    "        random.Random(seed).shuffle(nodes)\n",
    "        start_node = nodes[0]\n",
    "\n",
    "    sampled_nodes = set([start_node])\n",
    "    node_queue = [start_node]\n",
    "\n",
    "    while len(sampled_nodes) < number_of_nodes and node_queue:\n",
    "        current = node_queue.pop(0)\n",
    "        neighbors = sorted(list(graph.neighbors(current)))\n",
    "        random.Random(seed).shuffle(neighbors)\n",
    "\n",
    "        for neighbor in neighbors:\n",
    "            if len(sampled_nodes) >= number_of_nodes:\n",
    "                break\n",
    "            if neighbor not in sampled_nodes:\n",
    "                sampled_nodes.add(neighbor)\n",
    "                node_queue.append(neighbor)\n",
    "\n",
    "    return graph.subgraph(sampled_nodes)\n",
    "\n",
    "# Function to generate edge embeddings\n",
    "def generate_edge_embeddings(edges, embedding_function):\n",
    "    edge_embeddings = []\n",
    "    for u, v in edges:\n",
    "        u_embedding = embedding_function(u)\n",
    "        v_embedding = embedding_function(v)\n",
    "        edge_embedding = np.multiply(u_embedding, v_embedding)\n",
    "        edge_embeddings.append(edge_embedding)\n",
    "    return np.array(edge_embeddings)\n",
    "\n",
    "# Function to split the graph into train and test sets, ensuring connectivity\n",
    "def split_graph_with_connectivity(graph, fraction_to_remove=0.1, seed=None):\n",
    "    edge_list = list(graph.edges())\n",
    "    num_edges_to_remove = int(fraction_to_remove * graph.number_of_edges())\n",
    "\n",
    "    while True:\n",
    "        random.Random(seed).shuffle(edge_list)\n",
    "        edges_to_remove = edge_list[:num_edges_to_remove]\n",
    "        G_train = graph.copy()\n",
    "        G_train.remove_edges_from(edges_to_remove)\n",
    "        if nx.is_connected(G_train):\n",
    "            break\n",
    "\n",
    "    G_test = graph.copy()\n",
    "    G_test.remove_edges_from(G_train.edges())\n",
    "\n",
    "    return G_train, G_test, edges_to_remove\n",
    "\n",
    "# Function to generate positive and negative samples\n",
    "def generate_samples(graph, seed=None):\n",
    "    positive_samples = list(graph.edges())\n",
    "    negative_samples = []\n",
    "    all_nodes = sorted(list(graph.nodes()))\n",
    "\n",
    "    while len(negative_samples) < len(positive_samples):\n",
    "        node_pair = random.sample(all_nodes, 2)\n",
    "        if not graph.has_edge(*node_pair):\n",
    "            negative_samples.append(tuple(sorted(node_pair)))\n",
    "\n",
    "    return positive_samples, negative_samples\n",
    "\n",
    "# Function to generate Node2Vec embeddings\n",
    "def generate_node2vec_embeddings(graph, dimensions=128, num_walks=10, walk_length=5, p=1.0, q=1.0, seed=None):\n",
    "    # Function to perform random walk based on Node2Vec algorithm\n",
    "    def node2vec_walk(node):\n",
    "        walk = [node]\n",
    "        for _ in range(walk_length):\n",
    "            neighbors = list(graph.neighbors(walk[-1]))\n",
    "            if len(neighbors) > 0:\n",
    "                if len(walk) == 1:\n",
    "                    walk.append(random.choice(neighbors))\n",
    "                else:\n",
    "                    prev_node = walk[-2]\n",
    "                    probs = []\n",
    "                    for neighbor in neighbors:\n",
    "                        if neighbor == prev_node:\n",
    "                            probs.append(1 / p)\n",
    "                        elif graph.has_edge(prev_node, neighbor):\n",
    "                            probs.append(1)\n",
    "                        else:\n",
    "                            probs.append(1 / q)\n",
    "                    probs = np.array(probs)\n",
    "                    probs /= np.sum(probs)\n",
    "                    walk.append(np.random.choice(neighbors, p=probs))\n",
    "            else:\n",
    "                break\n",
    "        return walk\n",
    "\n",
    "    # Generating random walks\n",
    "    walks = []\n",
    "    nodes = list(graph.nodes())\n",
    "    for _ in range(num_walks):\n",
    "        random.seed(seed)\n",
    "        random.shuffle(nodes)\n",
    "        for node in nodes:\n",
    "            walks.append(node2vec_walk(node))\n",
    "\n",
    "    # Learning embeddings using Word2Vec with a fixed seed\n",
    "    embeddings = {}\n",
    "    model = Word2Vec(walks, vector_size=dimensions, window=5, min_count=1, sg=1, workers=1, seed=seed)\n",
    "    for node in nodes:\n",
    "        embeddings[node] = model.wv[node]\n",
    "\n",
    "    # Function to get node embeddings\n",
    "    def embedding_function(u):\n",
    "        return embeddings[u]\n",
    "\n",
    "    return model, embedding_function\n",
    "\n",
    "# Grid search over p, q ∈ {0.25, 0.50, 1, 2}\n",
    "p_values = [0.25, 0.5, 1, 2]\n",
    "q_values = [0.25, 0.5, 1, 2]\n",
    "\n",
    "# DataFrame to store the results\n",
    "results_df = pd.DataFrame(columns=['seed', 'p', 'q', 'roc_auc'])\n",
    "\n",
    "for seed in range(45,46):\n",
    "    # Set the new random seed for all functions\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "    # Load the data and create the graph\n",
    "    edge_list = load_edgelist('wiki.txt') # Replace with your actual file path\n",
    "    G = nx.Graph()\n",
    "    G.add_edges_from(edge_list)\n",
    "\n",
    "    # Sample subgraph, split into train/test, generate samples\n",
    "    subgraph = sample_subgraph_bfs(G, number_of_nodes=300, seed=seed)\n",
    "    G_train, G_test, _ = split_graph_with_connectivity(subgraph, seed=seed)\n",
    "    positive_samples_train, negative_samples_train = generate_samples(G_train, seed=seed)\n",
    "    positive_samples_test, negative_samples_test = generate_samples(G_test, seed=seed)\n",
    "\n",
    "    for p in p_values:\n",
    "        for q in q_values:\n",
    "            # Node2Vec embeddings\n",
    "            _, embedding_function = generate_node2vec_embeddings(G_train, p=p, q=q, seed=seed)\n",
    "\n",
    "            # Generate edge embeddings\n",
    "            edge_embeddings_train = generate_edge_embeddings(positive_samples_train + negative_samples_train, embedding_function)\n",
    "            edge_embeddings_test = generate_edge_embeddings(positive_samples_test + negative_samples_test, embedding_function)\n",
    "\n",
    "            # Logistic Regression Model\n",
    "            labels_train = np.array([1] * len(positive_samples_train) + [0] * len(negative_samples_train))\n",
    "            lr_clf = LogisticRegressionCV(cv=10, max_iter=2000, scoring=\"roc_auc\", random_state=seed)\n",
    "            classifier = lr_clf.fit(edge_embeddings_train, labels_train)\n",
    "\n",
    "            # Evaluate the model\n",
    "            labels_test = np.array([1] * len(positive_samples_test) + [0] * len(negative_samples_test))\n",
    "            test_predictions = classifier.predict_proba(edge_embeddings_test)[:, 1]\n",
    "            test_roc_auc = roc_auc_score(labels_test, test_predictions)\n",
    "\n",
    "            # Store results\n",
    "            results_df = pd.concat([results_df, pd.DataFrame([{'seed': seed, 'p': p, 'q': q, 'roc_auc': test_roc_auc}])], ignore_index=True)\n",
    "\n",
    "# Print DataFrame\n",
    "print(results_df)\n",
    "\n",
    "# Find the best combination of p and q based on average ROC AUC\n",
    "best_combination = results_df.groupby(['p', 'q'])['roc_auc'].mean().idxmax()\n",
    "print(f\"Best combination of p and q: {best_combination}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best combination of p and q len 5: (0.25, 0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Walks split into [5,10,15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ayush\\AppData\\Local\\Temp\\ipykernel_7320\\2923814464.py:178: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_df = pd.concat([results_df, pd.DataFrame([{'seed': seed, 'p': p, 'q': q, 'roc_auc': test_roc_auc}])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   seed     p     q   roc_auc\n",
      "0    45  0.25  0.25  0.777922\n",
      "1    45  0.25  0.50  0.783931\n",
      "2    45  0.25  1.00  0.793084\n",
      "3    45  0.25  2.00  0.744453\n",
      "4    45  0.50  0.25  0.741309\n",
      "5    45  0.50  0.50  0.821098\n",
      "6    45  0.50  1.00  0.724852\n",
      "7    45  0.50  2.00  0.784209\n",
      "8    45  1.00  0.25  0.786982\n",
      "9    45  1.00  0.50  0.780788\n",
      "10   45  1.00  1.00  0.763591\n",
      "11   45  1.00  2.00  0.768029\n",
      "12   45  2.00  0.25  0.793454\n",
      "13   45  2.00  0.50  0.821468\n",
      "14   45  2.00  1.00  0.788369\n",
      "15   45  2.00  2.00  0.754530\n",
      "Best combination of p and q: (2.0, 0.5)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import networkx as nx\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Function to load edge list from a file\n",
    "def load_edgelist(file_path):\n",
    "    edges = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            edge = line.strip().split()\n",
    "            edges.append((edge[0], edge[1]))\n",
    "    return edges\n",
    "\n",
    "# Function to sample a subgraph using BFS\n",
    "def sample_subgraph_bfs(graph, start_node=None, number_of_nodes=1000, seed=None):\n",
    "    if start_node is None:\n",
    "        nodes = list(graph.nodes())\n",
    "        random.Random(seed).shuffle(nodes)\n",
    "        start_node = nodes[0]\n",
    "\n",
    "    sampled_nodes = set([start_node])\n",
    "    node_queue = [start_node]\n",
    "\n",
    "    while len(sampled_nodes) < number_of_nodes and node_queue:\n",
    "        current = node_queue.pop(0)\n",
    "        neighbors = sorted(list(graph.neighbors(current)))\n",
    "        random.Random(seed).shuffle(neighbors)\n",
    "\n",
    "        for neighbor in neighbors:\n",
    "            if len(sampled_nodes) >= number_of_nodes:\n",
    "                break\n",
    "            if neighbor not in sampled_nodes:\n",
    "                sampled_nodes.add(neighbor)\n",
    "                node_queue.append(neighbor)\n",
    "\n",
    "    return graph.subgraph(sampled_nodes)\n",
    "\n",
    "# Function to generate edge embeddings\n",
    "def generate_edge_embeddings(edges, embedding_function):\n",
    "    edge_embeddings = []\n",
    "    for u, v in edges:\n",
    "        u_embedding = embedding_function(u)\n",
    "        v_embedding = embedding_function(v)\n",
    "        edge_embedding = np.multiply(u_embedding, v_embedding)\n",
    "        edge_embeddings.append(edge_embedding)\n",
    "    return np.array(edge_embeddings)\n",
    "\n",
    "# Function to split the graph into train and test sets, ensuring connectivity\n",
    "def split_graph_with_connectivity(graph, fraction_to_remove=0.1, seed=None):\n",
    "    edge_list = list(graph.edges())\n",
    "    num_edges_to_remove = int(fraction_to_remove * graph.number_of_edges())\n",
    "\n",
    "    while True:\n",
    "        random.Random(seed).shuffle(edge_list)\n",
    "        edges_to_remove = edge_list[:num_edges_to_remove]\n",
    "        G_train = graph.copy()\n",
    "        G_train.remove_edges_from(edges_to_remove)\n",
    "        if nx.is_connected(G_train):\n",
    "            break\n",
    "\n",
    "    G_test = graph.copy()\n",
    "    G_test.remove_edges_from(G_train.edges())\n",
    "\n",
    "    return G_train, G_test, edges_to_remove\n",
    "\n",
    "# Function to generate positive and negative samples\n",
    "def generate_samples(graph, seed=None):\n",
    "    positive_samples = list(graph.edges())\n",
    "    negative_samples = []\n",
    "    all_nodes = sorted(list(graph.nodes()))\n",
    "\n",
    "    while len(negative_samples) < len(positive_samples):\n",
    "        node_pair = random.sample(all_nodes, 2)\n",
    "        if not graph.has_edge(*node_pair):\n",
    "            negative_samples.append(tuple(sorted(node_pair)))\n",
    "\n",
    "    return positive_samples, negative_samples\n",
    "\n",
    "def generate_node2vec_embeddings_multiscale(graph, dimensions=128, num_walks=10, walk_lengths=[5, 10, 15], p=1.0, q=1.0, seed=None):\n",
    "    def node2vec_walk(node, length):\n",
    "        walk = [node]\n",
    "        for _ in range(length):\n",
    "            neighbors = list(graph.neighbors(walk[-1]))\n",
    "            if len(neighbors) > 0:\n",
    "                if len(walk) == 1:\n",
    "                    walk.append(random.choice(neighbors))\n",
    "                else:\n",
    "                    prev_node = walk[-2]\n",
    "                    probs = []\n",
    "                    for neighbor in neighbors:\n",
    "                        if neighbor == prev_node:\n",
    "                            probs.append(1 / p)\n",
    "                        elif graph.has_edge(prev_node, neighbor):\n",
    "                            probs.append(1)\n",
    "                        else:\n",
    "                            probs.append(1 / q)\n",
    "                    probs = np.array(probs)\n",
    "                    probs /= np.sum(probs)\n",
    "                    walk.append(np.random.choice(neighbors, p=probs))\n",
    "            else:\n",
    "                break\n",
    "        return walk\n",
    "\n",
    "    walks = []\n",
    "    nodes = list(graph.nodes())\n",
    "    for _ in range(num_walks):\n",
    "        random.seed(seed)\n",
    "        random.shuffle(nodes)\n",
    "        for node in nodes:\n",
    "            for length in walk_lengths:\n",
    "                walks.append(node2vec_walk(node, length))\n",
    "\n",
    "    embeddings = {}\n",
    "    model = Word2Vec(walks, vector_size=dimensions, window=5, min_count=1, sg=1, workers=1, seed=seed)\n",
    "    for node in nodes:\n",
    "        embeddings[node] = model.wv[node]\n",
    "\n",
    "    def embedding_function(u):\n",
    "        return embeddings[u]\n",
    "\n",
    "    return model, embedding_function\n",
    "\n",
    "\n",
    "# Grid search over p, q ∈ {0.25, 0.50, 1, 2}\n",
    "p_values = [0.25, 0.5, 1, 2]\n",
    "q_values = [0.25, 0.5, 1, 2]\n",
    "\n",
    "# DataFrame to store the results\n",
    "results_df = pd.DataFrame(columns=['seed', 'p', 'q', 'roc_auc'])\n",
    "\n",
    "for seed in range(45,46):\n",
    "    # Set the new random seed for all functions\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "    # Load the data and create the graph\n",
    "    edge_list = load_edgelist('wiki.txt')# Replace with your actual file path\n",
    "    G = nx.Graph()\n",
    "    G.add_edges_from(edge_list)\n",
    "\n",
    "    # Sample subgraph, split into train/test, generate samples\n",
    "    subgraph = sample_subgraph_bfs(G, number_of_nodes=300, seed=seed)\n",
    "    G_train, G_test, _ = split_graph_with_connectivity(subgraph, seed=seed)\n",
    "    positive_samples_train, negative_samples_train = generate_samples(G_train, seed=seed)\n",
    "    positive_samples_test, negative_samples_test = generate_samples(G_test, seed=seed)\n",
    "\n",
    "    # Define the list of walk lengths for multi-scale sampling\n",
    "    walk_lengths = [5, 10, 15]  # Adjust this list based on the lengths you want to explore\n",
    "\n",
    "    for p in p_values:\n",
    "        for q in q_values:\n",
    "            # Node2Vec embeddings with multi-scale sampling\n",
    "            _, embedding_function = generate_node2vec_embeddings_multiscale(G_train, p=p, q=q, walk_lengths=walk_lengths, seed=seed)\n",
    "\n",
    "            # Generate edge embeddings\n",
    "            edge_embeddings_train = generate_edge_embeddings(positive_samples_train + negative_samples_train, embedding_function)\n",
    "            edge_embeddings_test = generate_edge_embeddings(positive_samples_test + negative_samples_test, embedding_function)\n",
    "\n",
    "            # Logistic Regression Model\n",
    "            labels_train = np.array([1] * len(positive_samples_train) + [0] * len(negative_samples_train))\n",
    "            lr_clf = LogisticRegressionCV(cv=10, max_iter=2000, scoring=\"roc_auc\", random_state=seed)\n",
    "            classifier = lr_clf.fit(edge_embeddings_train, labels_train)\n",
    "\n",
    "            # Evaluate the model\n",
    "            labels_test = np.array([1] * len(positive_samples_test) + [0] * len(negative_samples_test))\n",
    "            test_predictions = classifier.predict_proba(edge_embeddings_test)[:, 1]\n",
    "            test_roc_auc = roc_auc_score(labels_test, test_predictions)\n",
    "\n",
    "            # Store results\n",
    "            results_df = pd.concat([results_df, pd.DataFrame([{'seed': seed, 'p': p, 'q': q, 'roc_auc': test_roc_auc}])], ignore_index=True)\n",
    "\n",
    "# Print DataFrame\n",
    "print(results_df)\n",
    "\n",
    "# Find the best combination of p and q based on average ROC AUC\n",
    "best_combination = results_df.groupby(['p', 'q'])['roc_auc'].mean().idxmax()\n",
    "print(f\"Best combination of p and q: {best_combination}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
